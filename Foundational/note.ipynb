{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b29e80",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eb1187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection\\SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e754a8d",
   "metadata": {},
   "source": [
    "# Instruction Fine-Tuning (IFT) for Language Models\n",
    "\n",
    "## What is Instruction Fine-Tuning?\n",
    "\n",
    "Instruction fine-tuning is a **process of training a pretrained language model to better follow human instructions**.  \n",
    "- The model learns **how to respond** to prompts, not just predict the next token.  \n",
    "- The underlying architecture (transformer, attention, embeddings) remains the same.  \n",
    "- Only the **training data and task** change.\n",
    "\n",
    "---\n",
    "\n",
    "## Why It’s Needed\n",
    "\n",
    "A standard pretrained model like GPT-2 or LLaMA is trained with **next-token prediction** on large text corpora.  \n",
    "\n",
    "### Behavior without instruction fine-tuning:\n",
    "- The model only **continues text**.  \n",
    "- It doesn’t understand “question vs statement” or “instruction vs story”.  \n",
    "- Outputs may be **irrelevant, confusing, or unsafe** if given an instruction.  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Prompt:  \n",
    "Translate English to French: I love programming.\n",
    "\n",
    "\n",
    "GPT-2 (vanilla) completion might output:  \n",
    "I love programming. It was a sunny day and the...\n",
    "\n",
    "- It’s continuing text, **not translating**.  \n",
    "- The model doesn’t recognize this as an instruction.\n",
    "\n",
    "---\n",
    "\n",
    "## How Instruction Fine-Tuning Works\n",
    "\n",
    "1. Start with a **pretrained model**.  \n",
    "2. Prepare a dataset of **instruction-response pairs**:\n",
    "   ```json\n",
    "   {\n",
    "     \"instruction\": \"Translate English to French: I love programming.\",\n",
    "     \"response\": \"J'aime programmer.\"\n",
    "   }\n",
    "   \n",
    "Prompt:\n",
    "\n",
    "Translate English to French: I love programming.\n",
    "# output\n",
    "J'aime programmer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4246140",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
