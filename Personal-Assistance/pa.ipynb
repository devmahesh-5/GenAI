{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5b6ef095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 52002\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "import ssl\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url, context=ssl_context) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            text_data = file.read()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/refs/heads\"\n",
    "    \"/main/alpaca_data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a0fb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Evaluate the following phrase by transforming it into the spelling given.',\n",
       " 'input': 'freind --> friend',\n",
       " 'output': 'The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af70c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee09c7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence.\n",
      "\n",
      "### Input:\n",
      "The lecture was delivered in a clear manner.\n"
     ]
    }
   ],
   "source": [
    "print(format_input(data[940]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0638bfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = format_input(data[940]) + (f\"\\n\\n### Response\\n{data[940]['output']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40e70eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence.\n",
      "\n",
      "### Input:\n",
      "The lecture was delivered in a clear manner.\n",
      "\n",
      "### Response\n",
      "The lecture was delivered clearly.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4efbe86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26001\n"
     ]
    }
   ],
   "source": [
    "# train_data = int(len(data)*0.7)\n",
    "# test_data = int(len(data)*0.2)\n",
    "# validate_data = int(len(data)*0.1)\n",
    "train_data = data[:int(len(data)*0.5)]\n",
    "test_data = data[int(len(data)*0.5):int(len(data)*0.05)+int(len(data)*0.5)]\n",
    "validate_data = data[int(len(data)*0.95):]\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c2ee789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2600\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72cd304d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601\n"
     ]
    }
   ],
   "source": [
    "print(len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e089d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b4dbbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d66f842c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Instruction_Dataset(Dataset):\n",
    "    def __init__(self,data, tokenizer):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.encoded = []\n",
    "\n",
    "        for entry in data:\n",
    "            instruction_input = format(entry)\n",
    "            response = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_entry = instruction_input + response\n",
    "            self.encoded.append(tokenizer.encode(full_entry))\n",
    "\n",
    "    def __getitem__(self, index) :\n",
    "        return self.encoded[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3540685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76e5b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now what we will do is we want in each batch every input and target sequence to have same length we ensure that by first adding 1 more 50256 token id to each sequences (sequence having less no of token than the sequence having highest no of token will also have max_len - len +1 later while returning on input we will exclude last token in each sequence) \n",
    "# now to get target sequence coressponding to each input sequence we shidt input sequence by 1 towards left and last token will be the 50256\n",
    "# Also for the target tensor or sequence we replace all the end of text token with -100 except the 1st one in the sequence which allows cross entropy loss function to ignore these tokens while calculating loss later\n",
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    # Find the longest sequence in the batch\n",
    "    batch_max_length = max(len(item)+1 for item in batch)\n",
    "\n",
    "    # Pad and prepare inputs and targets\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        # Add an <|endoftext|> token\n",
    "        new_item += [pad_token_id]\n",
    "        # Pad sequences to max_length\n",
    "        padded = (\n",
    "            new_item + [pad_token_id] *\n",
    "            (batch_max_length - len(new_item))\n",
    "        )\n",
    "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
    "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
    "\n",
    "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        # New: Optionally truncate to maximum sequence length\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    # Convert list of inputs and targets to tensors and transfer to target device\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564a641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "# lets test with dummy input batches\n",
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "\n",
    "batch = (\n",
    "    inputs_1,\n",
    "    inputs_2,\n",
    "    inputs_3\n",
    ")\n",
    "\n",
    "inputs, targets = custom_collate_fn(batch)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbc0785c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it is time to work on data loaders which allows to have multiple batches by arranging the input sequences in a batch of batch size \n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42818ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n",
      "12.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.backends.cudnn.enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40f8dcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall torch torchvision torchaudio -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1957d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pyenv local 3.11.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "756ee7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94e83818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "568dbc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)#it will auto give the custom_collate_fn these parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8037083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b86394af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "train_dataset = Instruction_Dataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = Instruction_Dataset(validate_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = Instruction_Dataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=customized_collate_fn,#after arranging the sequences in batch of batchsize no of sequences the batch is passed to collate_fn which returns the batch with target sequences also \n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8addcfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 594]) torch.Size([8, 594])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 470]) torch.Size([8, 470])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 180]) torch.Size([8, 180])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 156]) torch.Size([8, 156])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 439]) torch.Size([8, 439])\n",
      "torch.Size([8, 489]) torch.Size([8, 489])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 421]) torch.Size([8, 421])\n",
      "torch.Size([8, 552]) torch.Size([8, 552])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 383]) torch.Size([8, 383])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 686]) torch.Size([8, 686])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 558]) torch.Size([8, 558])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 196]) torch.Size([8, 196])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 189]) torch.Size([8, 189])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 463]) torch.Size([8, 463])\n",
      "torch.Size([8, 470]) torch.Size([8, 470])\n",
      "torch.Size([8, 422]) torch.Size([8, 422])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 401]) torch.Size([8, 401])\n",
      "torch.Size([8, 160]) torch.Size([8, 160])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 347]) torch.Size([8, 347])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 597]) torch.Size([8, 597])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 412]) torch.Size([8, 412])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 579]) torch.Size([8, 579])\n",
      "torch.Size([8, 443]) torch.Size([8, 443])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 546]) torch.Size([8, 546])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 569]) torch.Size([8, 569])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 168]) torch.Size([8, 168])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 718]) torch.Size([8, 718])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 405]) torch.Size([8, 405])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 214]) torch.Size([8, 214])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 734]) torch.Size([8, 734])\n",
      "torch.Size([8, 567]) torch.Size([8, 567])\n",
      "torch.Size([8, 596]) torch.Size([8, 596])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 567]) torch.Size([8, 567])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 622]) torch.Size([8, 622])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 508]) torch.Size([8, 508])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 943]) torch.Size([8, 943])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 653]) torch.Size([8, 653])\n",
      "torch.Size([8, 214]) torch.Size([8, 214])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 454]) torch.Size([8, 454])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 546]) torch.Size([8, 546])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 538]) torch.Size([8, 538])\n",
      "torch.Size([8, 506]) torch.Size([8, 506])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 568]) torch.Size([8, 568])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 391]) torch.Size([8, 391])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 626]) torch.Size([8, 626])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 323]) torch.Size([8, 323])\n",
      "torch.Size([8, 487]) torch.Size([8, 487])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 173]) torch.Size([8, 173])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 423]) torch.Size([8, 423])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 539]) torch.Size([8, 539])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 500]) torch.Size([8, 500])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 214]) torch.Size([8, 214])\n",
      "torch.Size([8, 200]) torch.Size([8, 200])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 431]) torch.Size([8, 431])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 492]) torch.Size([8, 492])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 373]) torch.Size([8, 373])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 493]) torch.Size([8, 493])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 505]) torch.Size([8, 505])\n",
      "torch.Size([8, 174]) torch.Size([8, 174])\n",
      "torch.Size([8, 568]) torch.Size([8, 568])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 457]) torch.Size([8, 457])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 481]) torch.Size([8, 481])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 383]) torch.Size([8, 383])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 161]) torch.Size([8, 161])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 627]) torch.Size([8, 627])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 148]) torch.Size([8, 148])\n",
      "torch.Size([8, 391]) torch.Size([8, 391])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 171]) torch.Size([8, 171])\n",
      "torch.Size([8, 431]) torch.Size([8, 431])\n",
      "torch.Size([8, 417]) torch.Size([8, 417])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 589]) torch.Size([8, 589])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 447]) torch.Size([8, 447])\n",
      "torch.Size([8, 540]) torch.Size([8, 540])\n",
      "torch.Size([8, 617]) torch.Size([8, 617])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 189]) torch.Size([8, 189])\n",
      "torch.Size([8, 424]) torch.Size([8, 424])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 146]) torch.Size([8, 146])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 467]) torch.Size([8, 467])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 214]) torch.Size([8, 214])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 745]) torch.Size([8, 745])\n",
      "torch.Size([8, 772]) torch.Size([8, 772])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 548]) torch.Size([8, 548])\n",
      "torch.Size([8, 188]) torch.Size([8, 188])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 732]) torch.Size([8, 732])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 161]) torch.Size([8, 161])\n",
      "torch.Size([8, 528]) torch.Size([8, 528])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 180]) torch.Size([8, 180])\n",
      "torch.Size([8, 119]) torch.Size([8, 119])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 457]) torch.Size([8, 457])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 171]) torch.Size([8, 171])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 517]) torch.Size([8, 517])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 423]) torch.Size([8, 423])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 837]) torch.Size([8, 837])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 542]) torch.Size([8, 542])\n",
      "torch.Size([8, 580]) torch.Size([8, 580])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 141]) torch.Size([8, 141])\n",
      "torch.Size([8, 451]) torch.Size([8, 451])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 861]) torch.Size([8, 861])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 853]) torch.Size([8, 853])\n",
      "torch.Size([8, 442]) torch.Size([8, 442])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 540]) torch.Size([8, 540])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 716]) torch.Size([8, 716])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 376]) torch.Size([8, 376])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 544]) torch.Size([8, 544])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 650]) torch.Size([8, 650])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 508]) torch.Size([8, 508])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 180]) torch.Size([8, 180])\n",
      "torch.Size([8, 683]) torch.Size([8, 683])\n",
      "torch.Size([8, 462]) torch.Size([8, 462])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 568]) torch.Size([8, 568])\n",
      "torch.Size([8, 766]) torch.Size([8, 766])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 416]) torch.Size([8, 416])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 112]) torch.Size([8, 112])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 376]) torch.Size([8, 376])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 401]) torch.Size([8, 401])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 506]) torch.Size([8, 506])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 388]) torch.Size([8, 388])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 570]) torch.Size([8, 570])\n",
      "torch.Size([8, 550]) torch.Size([8, 550])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 421]) torch.Size([8, 421])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 455]) torch.Size([8, 455])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 465]) torch.Size([8, 465])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 513]) torch.Size([8, 513])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 392]) torch.Size([8, 392])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 529]) torch.Size([8, 529])\n",
      "torch.Size([8, 567]) torch.Size([8, 567])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 157]) torch.Size([8, 157])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 626]) torch.Size([8, 626])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 571]) torch.Size([8, 571])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 844]) torch.Size([8, 844])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 193]) torch.Size([8, 193])\n",
      "torch.Size([8, 546]) torch.Size([8, 546])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 444]) torch.Size([8, 444])\n",
      "torch.Size([8, 569]) torch.Size([8, 569])\n",
      "torch.Size([8, 476]) torch.Size([8, 476])\n",
      "torch.Size([8, 429]) torch.Size([8, 429])\n",
      "torch.Size([8, 628]) torch.Size([8, 628])\n",
      "torch.Size([8, 637]) torch.Size([8, 637])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 193]) torch.Size([8, 193])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 123]) torch.Size([8, 123])\n",
      "torch.Size([8, 404]) torch.Size([8, 404])\n",
      "torch.Size([8, 634]) torch.Size([8, 634])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 168]) torch.Size([8, 168])\n",
      "torch.Size([8, 323]) torch.Size([8, 323])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 360]) torch.Size([8, 360])\n",
      "torch.Size([8, 452]) torch.Size([8, 452])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 153]) torch.Size([8, 153])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 413]) torch.Size([8, 413])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 429]) torch.Size([8, 429])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 147]) torch.Size([8, 147])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 474]) torch.Size([8, 474])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 691]) torch.Size([8, 691])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 449]) torch.Size([8, 449])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 386]) torch.Size([8, 386])\n",
      "torch.Size([8, 853]) torch.Size([8, 853])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 425]) torch.Size([8, 425])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 387]) torch.Size([8, 387])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 214]) torch.Size([8, 214])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 443]) torch.Size([8, 443])\n",
      "torch.Size([8, 590]) torch.Size([8, 590])\n",
      "torch.Size([8, 199]) torch.Size([8, 199])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 172]) torch.Size([8, 172])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 538]) torch.Size([8, 538])\n",
      "torch.Size([8, 403]) torch.Size([8, 403])\n",
      "torch.Size([8, 612]) torch.Size([8, 612])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 459]) torch.Size([8, 459])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 162]) torch.Size([8, 162])\n",
      "torch.Size([8, 491]) torch.Size([8, 491])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 450]) torch.Size([8, 450])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 598]) torch.Size([8, 598])\n",
      "torch.Size([8, 150]) torch.Size([8, 150])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 462]) torch.Size([8, 462])\n",
      "torch.Size([8, 469]) torch.Size([8, 469])\n",
      "torch.Size([8, 408]) torch.Size([8, 408])\n",
      "torch.Size([8, 438]) torch.Size([8, 438])\n",
      "torch.Size([8, 402]) torch.Size([8, 402])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 521]) torch.Size([8, 521])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 409]) torch.Size([8, 409])\n",
      "torch.Size([8, 611]) torch.Size([8, 611])\n",
      "torch.Size([8, 765]) torch.Size([8, 765])\n",
      "torch.Size([8, 706]) torch.Size([8, 706])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 648]) torch.Size([8, 648])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 457]) torch.Size([8, 457])\n",
      "torch.Size([8, 615]) torch.Size([8, 615])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 188]) torch.Size([8, 188])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 587]) torch.Size([8, 587])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 673]) torch.Size([8, 673])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 184]) torch.Size([8, 184])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 457]) torch.Size([8, 457])\n",
      "torch.Size([8, 424]) torch.Size([8, 424])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 619]) torch.Size([8, 619])\n",
      "torch.Size([8, 503]) torch.Size([8, 503])\n",
      "torch.Size([8, 424]) torch.Size([8, 424])\n",
      "torch.Size([8, 450]) torch.Size([8, 450])\n",
      "torch.Size([8, 715]) torch.Size([8, 715])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 410]) torch.Size([8, 410])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 440]) torch.Size([8, 440])\n",
      "torch.Size([8, 524]) torch.Size([8, 524])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 572]) torch.Size([8, 572])\n",
      "torch.Size([8, 181]) torch.Size([8, 181])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 566]) torch.Size([8, 566])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 174]) torch.Size([8, 174])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 397]) torch.Size([8, 397])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 430]) torch.Size([8, 430])\n",
      "torch.Size([8, 555]) torch.Size([8, 555])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 990]) torch.Size([8, 990])\n",
      "torch.Size([8, 742]) torch.Size([8, 742])\n",
      "torch.Size([8, 410]) torch.Size([8, 410])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 469]) torch.Size([8, 469])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 953]) torch.Size([8, 953])\n",
      "torch.Size([8, 424]) torch.Size([8, 424])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 479]) torch.Size([8, 479])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 457]) torch.Size([8, 457])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 144]) torch.Size([8, 144])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 484]) torch.Size([8, 484])\n",
      "torch.Size([8, 439]) torch.Size([8, 439])\n",
      "torch.Size([8, 704]) torch.Size([8, 704])\n",
      "torch.Size([8, 625]) torch.Size([8, 625])\n",
      "torch.Size([8, 526]) torch.Size([8, 526])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 619]) torch.Size([8, 619])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 545]) torch.Size([8, 545])\n",
      "torch.Size([8, 676]) torch.Size([8, 676])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 477]) torch.Size([8, 477])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 200]) torch.Size([8, 200])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 461]) torch.Size([8, 461])\n",
      "torch.Size([8, 1005]) torch.Size([8, 1005])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 228]) torch.Size([8, 228])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 492]) torch.Size([8, 492])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 360]) torch.Size([8, 360])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 161]) torch.Size([8, 161])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 579]) torch.Size([8, 579])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 399]) torch.Size([8, 399])\n",
      "torch.Size([8, 348]) torch.Size([8, 348])\n",
      "torch.Size([8, 576]) torch.Size([8, 576])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 532]) torch.Size([8, 532])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 460]) torch.Size([8, 460])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 184]) torch.Size([8, 184])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 384]) torch.Size([8, 384])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 491]) torch.Size([8, 491])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 392]) torch.Size([8, 392])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 143]) torch.Size([8, 143])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 145]) torch.Size([8, 145])\n",
      "torch.Size([8, 210]) torch.Size([8, 210])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 712]) torch.Size([8, 712])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 532]) torch.Size([8, 532])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 188]) torch.Size([8, 188])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 551]) torch.Size([8, 551])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 864]) torch.Size([8, 864])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 422]) torch.Size([8, 422])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 182]) torch.Size([8, 182])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 358]) torch.Size([8, 358])\n",
      "torch.Size([8, 409]) torch.Size([8, 409])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 428]) torch.Size([8, 428])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 597]) torch.Size([8, 597])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 528]) torch.Size([8, 528])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 755]) torch.Size([8, 755])\n",
      "torch.Size([8, 450]) torch.Size([8, 450])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 439]) torch.Size([8, 439])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 348]) torch.Size([8, 348])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 469]) torch.Size([8, 469])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 612]) torch.Size([8, 612])\n",
      "torch.Size([8, 684]) torch.Size([8, 684])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 419]) torch.Size([8, 419])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 480]) torch.Size([8, 480])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 630]) torch.Size([8, 630])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 347]) torch.Size([8, 347])\n",
      "torch.Size([8, 565]) torch.Size([8, 565])\n",
      "torch.Size([8, 502]) torch.Size([8, 502])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 728]) torch.Size([8, 728])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 462]) torch.Size([8, 462])\n",
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 390]) torch.Size([8, 390])\n",
      "torch.Size([8, 323]) torch.Size([8, 323])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 531]) torch.Size([8, 531])\n",
      "torch.Size([8, 375]) torch.Size([8, 375])\n",
      "torch.Size([8, 558]) torch.Size([8, 558])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 475]) torch.Size([8, 475])\n",
      "torch.Size([8, 145]) torch.Size([8, 145])\n",
      "torch.Size([8, 426]) torch.Size([8, 426])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 187]) torch.Size([8, 187])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 513]) torch.Size([8, 513])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 599]) torch.Size([8, 599])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 199]) torch.Size([8, 199])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 185]) torch.Size([8, 185])\n",
      "torch.Size([8, 439]) torch.Size([8, 439])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 533]) torch.Size([8, 533])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 123]) torch.Size([8, 123])\n",
      "torch.Size([8, 390]) torch.Size([8, 390])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 444]) torch.Size([8, 444])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 879]) torch.Size([8, 879])\n",
      "torch.Size([8, 695]) torch.Size([8, 695])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 784]) torch.Size([8, 784])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 438]) torch.Size([8, 438])\n",
      "torch.Size([8, 635]) torch.Size([8, 635])\n",
      "torch.Size([8, 409]) torch.Size([8, 409])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 426]) torch.Size([8, 426])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 442]) torch.Size([8, 442])\n",
      "torch.Size([8, 408]) torch.Size([8, 408])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 459]) torch.Size([8, 459])\n",
      "torch.Size([8, 453]) torch.Size([8, 453])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 548]) torch.Size([8, 548])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 371]) torch.Size([8, 371])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 624]) torch.Size([8, 624])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 572]) torch.Size([8, 572])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 557]) torch.Size([8, 557])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 551]) torch.Size([8, 551])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 533]) torch.Size([8, 533])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 170]) torch.Size([8, 170])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 408]) torch.Size([8, 408])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 529]) torch.Size([8, 529])\n",
      "torch.Size([8, 184]) torch.Size([8, 184])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 196]) torch.Size([8, 196])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 531]) torch.Size([8, 531])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 347]) torch.Size([8, 347])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 681]) torch.Size([8, 681])\n",
      "torch.Size([8, 399]) torch.Size([8, 399])\n",
      "torch.Size([8, 435]) torch.Size([8, 435])\n",
      "torch.Size([8, 191]) torch.Size([8, 191])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 158]) torch.Size([8, 158])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 149]) torch.Size([8, 149])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 413]) torch.Size([8, 413])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 685]) torch.Size([8, 685])\n",
      "torch.Size([8, 402]) torch.Size([8, 402])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 502]) torch.Size([8, 502])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 588]) torch.Size([8, 588])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 389]) torch.Size([8, 389])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 502]) torch.Size([8, 502])\n",
      "torch.Size([8, 150]) torch.Size([8, 150])\n",
      "torch.Size([8, 431]) torch.Size([8, 431])\n",
      "torch.Size([8, 153]) torch.Size([8, 153])\n",
      "torch.Size([8, 429]) torch.Size([8, 429])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 453]) torch.Size([8, 453])\n",
      "torch.Size([8, 461]) torch.Size([8, 461])\n",
      "torch.Size([8, 403]) torch.Size([8, 403])\n",
      "torch.Size([8, 454]) torch.Size([8, 454])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 405]) torch.Size([8, 405])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 409]) torch.Size([8, 409])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 464]) torch.Size([8, 464])\n",
      "torch.Size([8, 400]) torch.Size([8, 400])\n",
      "torch.Size([8, 456]) torch.Size([8, 456])\n",
      "torch.Size([8, 360]) torch.Size([8, 360])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 193]) torch.Size([8, 193])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 489]) torch.Size([8, 489])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 170]) torch.Size([8, 170])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 343]) torch.Size([8, 343])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 577]) torch.Size([8, 577])\n",
      "torch.Size([8, 182]) torch.Size([8, 182])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 623]) torch.Size([8, 623])\n",
      "torch.Size([8, 682]) torch.Size([8, 682])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 552]) torch.Size([8, 552])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 376]) torch.Size([8, 376])\n",
      "torch.Size([8, 484]) torch.Size([8, 484])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 678]) torch.Size([8, 678])\n",
      "torch.Size([8, 582]) torch.Size([8, 582])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 606]) torch.Size([8, 606])\n",
      "torch.Size([8, 426]) torch.Size([8, 426])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 416]) torch.Size([8, 416])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 580]) torch.Size([8, 580])\n",
      "torch.Size([8, 160]) torch.Size([8, 160])\n",
      "torch.Size([8, 436]) torch.Size([8, 436])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 439]) torch.Size([8, 439])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 670]) torch.Size([8, 670])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 419]) torch.Size([8, 419])\n",
      "torch.Size([8, 534]) torch.Size([8, 534])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 609]) torch.Size([8, 609])\n",
      "torch.Size([8, 470]) torch.Size([8, 470])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 703]) torch.Size([8, 703])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 401]) torch.Size([8, 401])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 420]) torch.Size([8, 420])\n",
      "torch.Size([8, 139]) torch.Size([8, 139])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 172]) torch.Size([8, 172])\n",
      "torch.Size([8, 448]) torch.Size([8, 448])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 449]) torch.Size([8, 449])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 558]) torch.Size([8, 558])\n",
      "torch.Size([8, 727]) torch.Size([8, 727])\n",
      "torch.Size([8, 540]) torch.Size([8, 540])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 638]) torch.Size([8, 638])\n",
      "torch.Size([8, 200]) torch.Size([8, 200])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 430]) torch.Size([8, 430])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 725]) torch.Size([8, 725])\n",
      "torch.Size([8, 618]) torch.Size([8, 618])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 720]) torch.Size([8, 720])\n",
      "torch.Size([8, 424]) torch.Size([8, 424])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 511]) torch.Size([8, 511])\n",
      "torch.Size([8, 191]) torch.Size([8, 191])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 409]) torch.Size([8, 409])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 548]) torch.Size([8, 548])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 412]) torch.Size([8, 412])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 574]) torch.Size([8, 574])\n",
      "torch.Size([8, 490]) torch.Size([8, 490])\n",
      "torch.Size([8, 529]) torch.Size([8, 529])\n",
      "torch.Size([8, 384]) torch.Size([8, 384])\n",
      "torch.Size([8, 680]) torch.Size([8, 680])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 403]) torch.Size([8, 403])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 511]) torch.Size([8, 511])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 576]) torch.Size([8, 576])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 526]) torch.Size([8, 526])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 685]) torch.Size([8, 685])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 429]) torch.Size([8, 429])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 464]) torch.Size([8, 464])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 458]) torch.Size([8, 458])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 587]) torch.Size([8, 587])\n",
      "torch.Size([8, 502]) torch.Size([8, 502])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 552]) torch.Size([8, 552])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 470]) torch.Size([8, 470])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 397]) torch.Size([8, 397])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 605]) torch.Size([8, 605])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 813]) torch.Size([8, 813])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 510]) torch.Size([8, 510])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 348]) torch.Size([8, 348])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 431]) torch.Size([8, 431])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 436]) torch.Size([8, 436])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 634]) torch.Size([8, 634])\n",
      "torch.Size([8, 668]) torch.Size([8, 668])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 448]) torch.Size([8, 448])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 196]) torch.Size([8, 196])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 473]) torch.Size([8, 473])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 374]) torch.Size([8, 374])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 420]) torch.Size([8, 420])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 671]) torch.Size([8, 671])\n",
      "torch.Size([8, 374]) torch.Size([8, 374])\n",
      "torch.Size([8, 400]) torch.Size([8, 400])\n",
      "torch.Size([8, 412]) torch.Size([8, 412])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 615]) torch.Size([8, 615])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 514]) torch.Size([8, 514])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 574]) torch.Size([8, 574])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 515]) torch.Size([8, 515])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 387]) torch.Size([8, 387])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 469]) torch.Size([8, 469])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 174]) torch.Size([8, 174])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 445]) torch.Size([8, 445])\n",
      "torch.Size([8, 397]) torch.Size([8, 397])\n",
      "torch.Size([8, 486]) torch.Size([8, 486])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 401]) torch.Size([8, 401])\n",
      "torch.Size([8, 228]) torch.Size([8, 228])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 532]) torch.Size([8, 532])\n",
      "torch.Size([8, 770]) torch.Size([8, 770])\n",
      "torch.Size([8, 490]) torch.Size([8, 490])\n",
      "torch.Size([8, 187]) torch.Size([8, 187])\n",
      "torch.Size([8, 487]) torch.Size([8, 487])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 135]) torch.Size([8, 135])\n",
      "torch.Size([8, 443]) torch.Size([8, 443])\n",
      "torch.Size([8, 452]) torch.Size([8, 452])\n",
      "torch.Size([8, 585]) torch.Size([8, 585])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 168]) torch.Size([8, 168])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 630]) torch.Size([8, 630])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 375]) torch.Size([8, 375])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 640]) torch.Size([8, 640])\n",
      "torch.Size([8, 404]) torch.Size([8, 404])\n",
      "torch.Size([8, 207]) torch.Size([8, 207])\n",
      "torch.Size([8, 218]) torch.Size([8, 218])\n",
      "torch.Size([8, 567]) torch.Size([8, 567])\n",
      "torch.Size([8, 498]) torch.Size([8, 498])\n",
      "torch.Size([8, 199]) torch.Size([8, 199])\n",
      "torch.Size([8, 969]) torch.Size([8, 969])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 530]) torch.Size([8, 530])\n",
      "torch.Size([8, 501]) torch.Size([8, 501])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 388]) torch.Size([8, 388])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 664]) torch.Size([8, 664])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 572]) torch.Size([8, 572])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 911]) torch.Size([8, 911])\n",
      "torch.Size([8, 462]) torch.Size([8, 462])\n",
      "torch.Size([8, 844]) torch.Size([8, 844])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 200]) torch.Size([8, 200])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 178]) torch.Size([8, 178])\n",
      "torch.Size([8, 501]) torch.Size([8, 501])\n",
      "torch.Size([8, 402]) torch.Size([8, 402])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 406]) torch.Size([8, 406])\n",
      "torch.Size([8, 433]) torch.Size([8, 433])\n",
      "torch.Size([8, 671]) torch.Size([8, 671])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 167]) torch.Size([8, 167])\n",
      "torch.Size([8, 210]) torch.Size([8, 210])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 160]) torch.Size([8, 160])\n",
      "torch.Size([8, 1005]) torch.Size([8, 1005])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 401]) torch.Size([8, 401])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 417]) torch.Size([8, 417])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 169]) torch.Size([8, 169])\n",
      "torch.Size([8, 402]) torch.Size([8, 402])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 360]) torch.Size([8, 360])\n",
      "torch.Size([8, 184]) torch.Size([8, 184])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 411]) torch.Size([8, 411])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 451]) torch.Size([8, 451])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 543]) torch.Size([8, 543])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 483]) torch.Size([8, 483])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 410]) torch.Size([8, 410])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 189]) torch.Size([8, 189])\n",
      "torch.Size([8, 472]) torch.Size([8, 472])\n",
      "torch.Size([8, 690]) torch.Size([8, 690])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 874]) torch.Size([8, 874])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 506]) torch.Size([8, 506])\n",
      "torch.Size([8, 480]) torch.Size([8, 480])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 528]) torch.Size([8, 528])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 161]) torch.Size([8, 161])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 392]) torch.Size([8, 392])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 521]) torch.Size([8, 521])\n",
      "torch.Size([8, 568]) torch.Size([8, 568])\n",
      "torch.Size([8, 504]) torch.Size([8, 504])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 489]) torch.Size([8, 489])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 191]) torch.Size([8, 191])\n",
      "torch.Size([8, 145]) torch.Size([8, 145])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 480]) torch.Size([8, 480])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 470]) torch.Size([8, 470])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 656]) torch.Size([8, 656])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 909]) torch.Size([8, 909])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 618]) torch.Size([8, 618])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 389]) torch.Size([8, 389])\n",
      "torch.Size([8, 574]) torch.Size([8, 574])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 840]) torch.Size([8, 840])\n",
      "torch.Size([8, 578]) torch.Size([8, 578])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 507]) torch.Size([8, 507])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 213]) torch.Size([8, 213])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 707]) torch.Size([8, 707])\n",
      "torch.Size([8, 946]) torch.Size([8, 946])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 360]) torch.Size([8, 360])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 464]) torch.Size([8, 464])\n",
      "torch.Size([8, 524]) torch.Size([8, 524])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 562]) torch.Size([8, 562])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 480]) torch.Size([8, 480])\n",
      "torch.Size([8, 438]) torch.Size([8, 438])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 473]) torch.Size([8, 473])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 481]) torch.Size([8, 481])\n",
      "torch.Size([8, 467]) torch.Size([8, 467])\n",
      "torch.Size([8, 474]) torch.Size([8, 474])\n",
      "torch.Size([8, 829]) torch.Size([8, 829])\n",
      "torch.Size([8, 461]) torch.Size([8, 461])\n",
      "torch.Size([8, 589]) torch.Size([8, 589])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 626]) torch.Size([8, 626])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 464]) torch.Size([8, 464])\n",
      "torch.Size([8, 498]) torch.Size([8, 498])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 199]) torch.Size([8, 199])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 501]) torch.Size([8, 501])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 595]) torch.Size([8, 595])\n",
      "torch.Size([8, 373]) torch.Size([8, 373])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 708]) torch.Size([8, 708])\n",
      "torch.Size([8, 527]) torch.Size([8, 527])\n",
      "torch.Size([8, 191]) torch.Size([8, 191])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 612]) torch.Size([8, 612])\n",
      "torch.Size([8, 525]) torch.Size([8, 525])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 165]) torch.Size([8, 165])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 570]) torch.Size([8, 570])\n",
      "torch.Size([8, 458]) torch.Size([8, 458])\n",
      "torch.Size([8, 510]) torch.Size([8, 510])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 578]) torch.Size([8, 578])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 735]) torch.Size([8, 735])\n",
      "torch.Size([8, 447]) torch.Size([8, 447])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 523]) torch.Size([8, 523])\n",
      "torch.Size([8, 531]) torch.Size([8, 531])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 145]) torch.Size([8, 145])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 413]) torch.Size([8, 413])\n",
      "torch.Size([8, 374]) torch.Size([8, 374])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 156]) torch.Size([8, 156])\n",
      "torch.Size([8, 190]) torch.Size([8, 190])\n",
      "torch.Size([8, 555]) torch.Size([8, 555])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 210]) torch.Size([8, 210])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 141]) torch.Size([8, 141])\n",
      "torch.Size([8, 191]) torch.Size([8, 191])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 435]) torch.Size([8, 435])\n",
      "torch.Size([8, 476]) torch.Size([8, 476])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 509]) torch.Size([8, 509])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 387]) torch.Size([8, 387])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 373]) torch.Size([8, 373])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 623]) torch.Size([8, 623])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 174]) torch.Size([8, 174])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 777]) torch.Size([8, 777])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 536]) torch.Size([8, 536])\n",
      "torch.Size([8, 776]) torch.Size([8, 776])\n",
      "torch.Size([8, 685]) torch.Size([8, 685])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 358]) torch.Size([8, 358])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 430]) torch.Size([8, 430])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 697]) torch.Size([8, 697])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 395]) torch.Size([8, 395])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 465]) torch.Size([8, 465])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 470]) torch.Size([8, 470])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 710]) torch.Size([8, 710])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 560]) torch.Size([8, 560])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 180]) torch.Size([8, 180])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 566]) torch.Size([8, 566])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 461]) torch.Size([8, 461])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 416]) torch.Size([8, 416])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 505]) torch.Size([8, 505])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 205]) torch.Size([8, 205])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 422]) torch.Size([8, 422])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 515]) torch.Size([8, 515])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 642]) torch.Size([8, 642])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 807]) torch.Size([8, 807])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 537]) torch.Size([8, 537])\n",
      "torch.Size([8, 153]) torch.Size([8, 153])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 537]) torch.Size([8, 537])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 587]) torch.Size([8, 587])\n",
      "torch.Size([8, 384]) torch.Size([8, 384])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 485]) torch.Size([8, 485])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 161]) torch.Size([8, 161])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 400]) torch.Size([8, 400])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 166]) torch.Size([8, 166])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 482]) torch.Size([8, 482])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 557]) torch.Size([8, 557])\n",
      "torch.Size([8, 432]) torch.Size([8, 432])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 555]) torch.Size([8, 555])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 507]) torch.Size([8, 507])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 445]) torch.Size([8, 445])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 323]) torch.Size([8, 323])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 527]) torch.Size([8, 527])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 409]) torch.Size([8, 409])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 181]) torch.Size([8, 181])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 603]) torch.Size([8, 603])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 418]) torch.Size([8, 418])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 798]) torch.Size([8, 798])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 471]) torch.Size([8, 471])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 582]) torch.Size([8, 582])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 766]) torch.Size([8, 766])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 182]) torch.Size([8, 182])\n",
      "torch.Size([8, 461]) torch.Size([8, 461])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 410]) torch.Size([8, 410])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 151]) torch.Size([8, 151])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 417]) torch.Size([8, 417])\n",
      "torch.Size([8, 489]) torch.Size([8, 489])\n",
      "torch.Size([8, 811]) torch.Size([8, 811])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 112]) torch.Size([8, 112])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 184]) torch.Size([8, 184])\n",
      "torch.Size([8, 434]) torch.Size([8, 434])\n",
      "torch.Size([8, 493]) torch.Size([8, 493])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 474]) torch.Size([8, 474])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 461]) torch.Size([8, 461])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 624]) torch.Size([8, 624])\n",
      "torch.Size([8, 557]) torch.Size([8, 557])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 609]) torch.Size([8, 609])\n",
      "torch.Size([8, 218]) torch.Size([8, 218])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 664]) torch.Size([8, 664])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 383]) torch.Size([8, 383])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 907]) torch.Size([8, 907])\n",
      "torch.Size([8, 387]) torch.Size([8, 387])\n",
      "torch.Size([8, 448]) torch.Size([8, 448])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 383]) torch.Size([8, 383])\n",
      "torch.Size([8, 544]) torch.Size([8, 544])\n",
      "torch.Size([8, 452]) torch.Size([8, 452])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 440]) torch.Size([8, 440])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 577]) torch.Size([8, 577])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 629]) torch.Size([8, 629])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 663]) torch.Size([8, 663])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 435]) torch.Size([8, 435])\n",
      "torch.Size([8, 596]) torch.Size([8, 596])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 163]) torch.Size([8, 163])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 215]) torch.Size([8, 215])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 138]) torch.Size([8, 138])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 456]) torch.Size([8, 456])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 720]) torch.Size([8, 720])\n",
      "torch.Size([8, 109]) torch.Size([8, 109])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 483]) torch.Size([8, 483])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 416]) torch.Size([8, 416])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 158]) torch.Size([8, 158])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 134]) torch.Size([8, 134])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 802]) torch.Size([8, 802])\n",
      "torch.Size([8, 592]) torch.Size([8, 592])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 538]) torch.Size([8, 538])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 605]) torch.Size([8, 605])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 817]) torch.Size([8, 817])\n",
      "torch.Size([8, 756]) torch.Size([8, 756])\n",
      "torch.Size([8, 405]) torch.Size([8, 405])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 535]) torch.Size([8, 535])\n",
      "torch.Size([8, 406]) torch.Size([8, 406])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 207]) torch.Size([8, 207])\n",
      "torch.Size([8, 411]) torch.Size([8, 411])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 561]) torch.Size([8, 561])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 162]) torch.Size([8, 162])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 739]) torch.Size([8, 739])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 498]) torch.Size([8, 498])\n",
      "torch.Size([8, 808]) torch.Size([8, 808])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 169]) torch.Size([8, 169])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 426]) torch.Size([8, 426])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 272]) torch.Size([8, 272])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 199]) torch.Size([8, 199])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 482]) torch.Size([8, 482])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 388]) torch.Size([8, 388])\n",
      "torch.Size([8, 436]) torch.Size([8, 436])\n",
      "torch.Size([8, 955]) torch.Size([8, 955])\n",
      "torch.Size([8, 189]) torch.Size([8, 189])\n",
      "torch.Size([8, 376]) torch.Size([8, 376])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 562]) torch.Size([8, 562])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 427]) torch.Size([8, 427])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 507]) torch.Size([8, 507])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 451]) torch.Size([8, 451])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 551]) torch.Size([8, 551])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 678]) torch.Size([8, 678])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 228]) torch.Size([8, 228])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 359]) torch.Size([8, 359])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 678]) torch.Size([8, 678])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 324]) torch.Size([8, 324])\n",
      "torch.Size([8, 495]) torch.Size([8, 495])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 561]) torch.Size([8, 561])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 421]) torch.Size([8, 421])\n",
      "torch.Size([8, 228]) torch.Size([8, 228])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 509]) torch.Size([8, 509])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 367]) torch.Size([8, 367])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 744]) torch.Size([8, 744])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 191]) torch.Size([8, 191])\n",
      "torch.Size([8, 405]) torch.Size([8, 405])\n",
      "torch.Size([8, 451]) torch.Size([8, 451])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 616]) torch.Size([8, 616])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 591]) torch.Size([8, 591])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 398]) torch.Size([8, 398])\n",
      "torch.Size([8, 390]) torch.Size([8, 390])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 177]) torch.Size([8, 177])\n",
      "torch.Size([8, 468]) torch.Size([8, 468])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 448]) torch.Size([8, 448])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 505]) torch.Size([8, 505])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 617]) torch.Size([8, 617])\n",
      "torch.Size([8, 455]) torch.Size([8, 455])\n",
      "torch.Size([8, 403]) torch.Size([8, 403])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 207]) torch.Size([8, 207])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 411]) torch.Size([8, 411])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 398]) torch.Size([8, 398])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 358]) torch.Size([8, 358])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 399]) torch.Size([8, 399])\n",
      "torch.Size([8, 616]) torch.Size([8, 616])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 912]) torch.Size([8, 912])\n",
      "torch.Size([8, 443]) torch.Size([8, 443])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 822]) torch.Size([8, 822])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 442]) torch.Size([8, 442])\n",
      "torch.Size([8, 454]) torch.Size([8, 454])\n",
      "torch.Size([8, 390]) torch.Size([8, 390])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 595]) torch.Size([8, 595])\n",
      "torch.Size([8, 487]) torch.Size([8, 487])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 465]) torch.Size([8, 465])\n",
      "torch.Size([8, 513]) torch.Size([8, 513])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 524]) torch.Size([8, 524])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 501]) torch.Size([8, 501])\n",
      "torch.Size([8, 405]) torch.Size([8, 405])\n",
      "torch.Size([8, 446]) torch.Size([8, 446])\n",
      "torch.Size([8, 348]) torch.Size([8, 348])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 514]) torch.Size([8, 514])\n",
      "torch.Size([8, 427]) torch.Size([8, 427])\n",
      "torch.Size([8, 601]) torch.Size([8, 601])\n",
      "torch.Size([8, 451]) torch.Size([8, 451])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 595]) torch.Size([8, 595])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 188]) torch.Size([8, 188])\n",
      "torch.Size([8, 424]) torch.Size([8, 424])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 178]) torch.Size([8, 178])\n",
      "torch.Size([8, 558]) torch.Size([8, 558])\n",
      "torch.Size([8, 119]) torch.Size([8, 119])\n",
      "torch.Size([8, 133]) torch.Size([8, 133])\n",
      "torch.Size([8, 466]) torch.Size([8, 466])\n",
      "torch.Size([8, 454]) torch.Size([8, 454])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 114]) torch.Size([8, 114])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 514]) torch.Size([8, 514])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 570]) torch.Size([8, 570])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 734]) torch.Size([8, 734])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 597]) torch.Size([8, 597])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 544]) torch.Size([8, 544])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 373]) torch.Size([8, 373])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 388]) torch.Size([8, 388])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 365]) torch.Size([8, 365])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 375]) torch.Size([8, 375])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 585]) torch.Size([8, 585])\n",
      "torch.Size([8, 465]) torch.Size([8, 465])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 415]) torch.Size([8, 415])\n",
      "torch.Size([8, 447]) torch.Size([8, 447])\n",
      "torch.Size([8, 523]) torch.Size([8, 523])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 254]) torch.Size([8, 254])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 128]) torch.Size([8, 128])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 171]) torch.Size([8, 171])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 210]) torch.Size([8, 210])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 446]) torch.Size([8, 446])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 519]) torch.Size([8, 519])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 855]) torch.Size([8, 855])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 396]) torch.Size([8, 396])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 355]) torch.Size([8, 355])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 402]) torch.Size([8, 402])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 444]) torch.Size([8, 444])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 459]) torch.Size([8, 459])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 581]) torch.Size([8, 581])\n",
      "torch.Size([8, 189]) torch.Size([8, 189])\n",
      "torch.Size([8, 577]) torch.Size([8, 577])\n",
      "torch.Size([8, 818]) torch.Size([8, 818])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 614]) torch.Size([8, 614])\n",
      "torch.Size([8, 406]) torch.Size([8, 406])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 611]) torch.Size([8, 611])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 413]) torch.Size([8, 413])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 406]) torch.Size([8, 406])\n",
      "torch.Size([8, 699]) torch.Size([8, 699])\n",
      "torch.Size([8, 689]) torch.Size([8, 689])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 192]) torch.Size([8, 192])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 476]) torch.Size([8, 476])\n",
      "torch.Size([8, 517]) torch.Size([8, 517])\n",
      "torch.Size([8, 476]) torch.Size([8, 476])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 185]) torch.Size([8, 185])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 202]) torch.Size([8, 202])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 143]) torch.Size([8, 143])\n",
      "torch.Size([8, 486]) torch.Size([8, 486])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 513]) torch.Size([8, 513])\n",
      "torch.Size([8, 520]) torch.Size([8, 520])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 539]) torch.Size([8, 539])\n",
      "torch.Size([8, 576]) torch.Size([8, 576])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 459]) torch.Size([8, 459])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 219]) torch.Size([8, 219])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 374]) torch.Size([8, 374])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 504]) torch.Size([8, 504])\n",
      "torch.Size([8, 536]) torch.Size([8, 536])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 553]) torch.Size([8, 553])\n",
      "torch.Size([8, 367]) torch.Size([8, 367])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 221]) torch.Size([8, 221])\n",
      "torch.Size([8, 146]) torch.Size([8, 146])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 537]) torch.Size([8, 537])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 149]) torch.Size([8, 149])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 347]) torch.Size([8, 347])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 637]) torch.Size([8, 637])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 511]) torch.Size([8, 511])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 361]) torch.Size([8, 361])\n",
      "torch.Size([8, 309]) torch.Size([8, 309])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 196]) torch.Size([8, 196])\n",
      "torch.Size([8, 412]) torch.Size([8, 412])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 382]) torch.Size([8, 382])\n",
      "torch.Size([8, 103]) torch.Size([8, 103])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 628]) torch.Size([8, 628])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 540]) torch.Size([8, 540])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 398]) torch.Size([8, 398])\n",
      "torch.Size([8, 546]) torch.Size([8, 546])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 492]) torch.Size([8, 492])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 408]) torch.Size([8, 408])\n",
      "torch.Size([8, 188]) torch.Size([8, 188])\n",
      "torch.Size([8, 416]) torch.Size([8, 416])\n",
      "torch.Size([8, 368]) torch.Size([8, 368])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 545]) torch.Size([8, 545])\n",
      "torch.Size([8, 317]) torch.Size([8, 317])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 764]) torch.Size([8, 764])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 514]) torch.Size([8, 514])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 597]) torch.Size([8, 597])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 575]) torch.Size([8, 575])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 912]) torch.Size([8, 912])\n",
      "torch.Size([8, 561]) torch.Size([8, 561])\n",
      "torch.Size([8, 535]) torch.Size([8, 535])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 614]) torch.Size([8, 614])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 408]) torch.Size([8, 408])\n",
      "torch.Size([8, 431]) torch.Size([8, 431])\n",
      "torch.Size([8, 441]) torch.Size([8, 441])\n",
      "torch.Size([8, 370]) torch.Size([8, 370])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 198]) torch.Size([8, 198])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 532]) torch.Size([8, 532])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 491]) torch.Size([8, 491])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 578]) torch.Size([8, 578])\n",
      "torch.Size([8, 210]) torch.Size([8, 210])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 398]) torch.Size([8, 398])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 367]) torch.Size([8, 367])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 192]) torch.Size([8, 192])\n",
      "torch.Size([8, 373]) torch.Size([8, 373])\n",
      "torch.Size([8, 465]) torch.Size([8, 465])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 328]) torch.Size([8, 328])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 686]) torch.Size([8, 686])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 546]) torch.Size([8, 546])\n",
      "torch.Size([8, 233]) torch.Size([8, 233])\n",
      "torch.Size([8, 195]) torch.Size([8, 195])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 190]) torch.Size([8, 190])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 538]) torch.Size([8, 538])\n",
      "torch.Size([8, 231]) torch.Size([8, 231])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 460]) torch.Size([8, 460])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 444]) torch.Size([8, 444])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 413]) torch.Size([8, 413])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 677]) torch.Size([8, 677])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 510]) torch.Size([8, 510])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 509]) torch.Size([8, 509])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 422]) torch.Size([8, 422])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 190]) torch.Size([8, 190])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 218]) torch.Size([8, 218])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 433]) torch.Size([8, 433])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 528]) torch.Size([8, 528])\n",
      "torch.Size([8, 550]) torch.Size([8, 550])\n",
      "torch.Size([8, 306]) torch.Size([8, 306])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 97]) torch.Size([8, 97])\n",
      "torch.Size([8, 342]) torch.Size([8, 342])\n",
      "torch.Size([8, 624]) torch.Size([8, 624])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 318]) torch.Size([8, 318])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 193]) torch.Size([8, 193])\n",
      "torch.Size([8, 384]) torch.Size([8, 384])\n",
      "torch.Size([8, 545]) torch.Size([8, 545])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 584]) torch.Size([8, 584])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 197]) torch.Size([8, 197])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 351]) torch.Size([8, 351])\n",
      "torch.Size([8, 181]) torch.Size([8, 181])\n",
      "torch.Size([8, 193]) torch.Size([8, 193])\n",
      "torch.Size([8, 610]) torch.Size([8, 610])\n",
      "torch.Size([8, 251]) torch.Size([8, 251])\n",
      "torch.Size([8, 200]) torch.Size([8, 200])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 662]) torch.Size([8, 662])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 377]) torch.Size([8, 377])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 259]) torch.Size([8, 259])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 513]) torch.Size([8, 513])\n",
      "torch.Size([8, 451]) torch.Size([8, 451])\n",
      "torch.Size([8, 686]) torch.Size([8, 686])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 749]) torch.Size([8, 749])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 247]) torch.Size([8, 247])\n",
      "torch.Size([8, 768]) torch.Size([8, 768])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 334]) torch.Size([8, 334])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 479]) torch.Size([8, 479])\n",
      "torch.Size([8, 338]) torch.Size([8, 338])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 116]) torch.Size([8, 116])\n",
      "torch.Size([8, 167]) torch.Size([8, 167])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 644]) torch.Size([8, 644])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 391]) torch.Size([8, 391])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 217]) torch.Size([8, 217])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 560]) torch.Size([8, 560])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 195]) torch.Size([8, 195])\n",
      "torch.Size([8, 300]) torch.Size([8, 300])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 428]) torch.Size([8, 428])\n",
      "torch.Size([8, 414]) torch.Size([8, 414])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 348]) torch.Size([8, 348])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 478]) torch.Size([8, 478])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 446]) torch.Size([8, 446])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 237]) torch.Size([8, 237])\n",
      "torch.Size([8, 375]) torch.Size([8, 375])\n",
      "torch.Size([8, 450]) torch.Size([8, 450])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 143]) torch.Size([8, 143])\n",
      "torch.Size([8, 576]) torch.Size([8, 576])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 709]) torch.Size([8, 709])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 447]) torch.Size([8, 447])\n",
      "torch.Size([8, 184]) torch.Size([8, 184])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 410]) torch.Size([8, 410])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 616]) torch.Size([8, 616])\n",
      "torch.Size([8, 439]) torch.Size([8, 439])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 352]) torch.Size([8, 352])\n",
      "torch.Size([8, 508]) torch.Size([8, 508])\n",
      "torch.Size([8, 454]) torch.Size([8, 454])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 565]) torch.Size([8, 565])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 526]) torch.Size([8, 526])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 260]) torch.Size([8, 260])\n",
      "torch.Size([8, 762]) torch.Size([8, 762])\n",
      "torch.Size([8, 684]) torch.Size([8, 684])\n",
      "torch.Size([8, 456]) torch.Size([8, 456])\n",
      "torch.Size([8, 452]) torch.Size([8, 452])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 471]) torch.Size([8, 471])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 624]) torch.Size([8, 624])\n",
      "torch.Size([8, 346]) torch.Size([8, 346])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 457]) torch.Size([8, 457])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 596]) torch.Size([8, 596])\n",
      "torch.Size([8, 214]) torch.Size([8, 214])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 210]) torch.Size([8, 210])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 323]) torch.Size([8, 323])\n",
      "torch.Size([8, 384]) torch.Size([8, 384])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 224]) torch.Size([8, 224])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 525]) torch.Size([8, 525])\n",
      "torch.Size([8, 171]) torch.Size([8, 171])\n",
      "torch.Size([8, 249]) torch.Size([8, 249])\n",
      "torch.Size([8, 245]) torch.Size([8, 245])\n",
      "torch.Size([8, 588]) torch.Size([8, 588])\n",
      "torch.Size([8, 311]) torch.Size([8, 311])\n",
      "torch.Size([8, 509]) torch.Size([8, 509])\n",
      "torch.Size([8, 160]) torch.Size([8, 160])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 289]) torch.Size([8, 289])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 305]) torch.Size([8, 305])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 693]) torch.Size([8, 693])\n",
      "torch.Size([8, 190]) torch.Size([8, 190])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 345]) torch.Size([8, 345])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 218]) torch.Size([8, 218])\n",
      "torch.Size([8, 201]) torch.Size([8, 201])\n",
      "torch.Size([8, 460]) torch.Size([8, 460])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 512]) torch.Size([8, 512])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 425]) torch.Size([8, 425])\n",
      "torch.Size([8, 477]) torch.Size([8, 477])\n",
      "torch.Size([8, 495]) torch.Size([8, 495])\n",
      "torch.Size([8, 1016]) torch.Size([8, 1016])\n",
      "torch.Size([8, 635]) torch.Size([8, 635])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 502]) torch.Size([8, 502])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 679]) torch.Size([8, 679])\n",
      "torch.Size([8, 421]) torch.Size([8, 421])\n",
      "torch.Size([8, 881]) torch.Size([8, 881])\n",
      "torch.Size([8, 384]) torch.Size([8, 384])\n",
      "torch.Size([8, 431]) torch.Size([8, 431])\n",
      "torch.Size([8, 566]) torch.Size([8, 566])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 220]) torch.Size([8, 220])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 398]) torch.Size([8, 398])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 561]) torch.Size([8, 561])\n",
      "torch.Size([8, 556]) torch.Size([8, 556])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 511]) torch.Size([8, 511])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 190]) torch.Size([8, 190])\n",
      "torch.Size([8, 288]) torch.Size([8, 288])\n",
      "torch.Size([8, 527]) torch.Size([8, 527])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 372]) torch.Size([8, 372])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 297]) torch.Size([8, 297])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 331]) torch.Size([8, 331])\n",
      "torch.Size([8, 517]) torch.Size([8, 517])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 216]) torch.Size([8, 216])\n",
      "torch.Size([8, 422]) torch.Size([8, 422])\n",
      "torch.Size([8, 383]) torch.Size([8, 383])\n",
      "torch.Size([8, 397]) torch.Size([8, 397])\n",
      "torch.Size([8, 138]) torch.Size([8, 138])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 378]) torch.Size([8, 378])\n",
      "torch.Size([8, 313]) torch.Size([8, 313])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 203]) torch.Size([8, 203])\n",
      "torch.Size([8, 672]) torch.Size([8, 672])\n",
      "torch.Size([8, 226]) torch.Size([8, 226])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 293]) torch.Size([8, 293])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 430]) torch.Size([8, 430])\n",
      "torch.Size([8, 423]) torch.Size([8, 423])\n",
      "torch.Size([8, 344]) torch.Size([8, 344])\n",
      "torch.Size([8, 416]) torch.Size([8, 416])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 285]) torch.Size([8, 285])\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n",
      "torch.Size([8, 528]) torch.Size([8, 528])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 232]) torch.Size([8, 232])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 350]) torch.Size([8, 350])\n",
      "torch.Size([8, 238]) torch.Size([8, 238])\n",
      "torch.Size([8, 496]) torch.Size([8, 496])\n",
      "torch.Size([8, 270]) torch.Size([8, 270])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 265]) torch.Size([8, 265])\n",
      "torch.Size([8, 607]) torch.Size([8, 607])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 657]) torch.Size([8, 657])\n",
      "torch.Size([8, 556]) torch.Size([8, 556])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 194]) torch.Size([8, 194])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 661]) torch.Size([8, 661])\n",
      "torch.Size([8, 256]) torch.Size([8, 256])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 283]) torch.Size([8, 283])\n",
      "torch.Size([8, 787]) torch.Size([8, 787])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 264]) torch.Size([8, 264])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 448]) torch.Size([8, 448])\n",
      "torch.Size([8, 518]) torch.Size([8, 518])\n",
      "torch.Size([8, 319]) torch.Size([8, 319])\n",
      "torch.Size([8, 501]) torch.Size([8, 501])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 277]) torch.Size([8, 277])\n",
      "torch.Size([8, 479]) torch.Size([8, 479])\n",
      "torch.Size([8, 565]) torch.Size([8, 565])\n",
      "torch.Size([8, 322]) torch.Size([8, 322])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 675]) torch.Size([8, 675])\n",
      "torch.Size([8, 497]) torch.Size([8, 497])\n",
      "torch.Size([8, 627]) torch.Size([8, 627])\n",
      "torch.Size([8, 255]) torch.Size([8, 255])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 585]) torch.Size([8, 585])\n",
      "torch.Size([8, 235]) torch.Size([8, 235])\n",
      "torch.Size([8, 307]) torch.Size([8, 307])\n",
      "torch.Size([8, 593]) torch.Size([8, 593])\n",
      "torch.Size([8, 323]) torch.Size([8, 323])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 943]) torch.Size([8, 943])\n",
      "torch.Size([8, 257]) torch.Size([8, 257])\n",
      "torch.Size([8, 303]) torch.Size([8, 303])\n",
      "torch.Size([8, 353]) torch.Size([8, 353])\n",
      "torch.Size([8, 315]) torch.Size([8, 315])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 407]) torch.Size([8, 407])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 371]) torch.Size([8, 371])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 176]) torch.Size([8, 176])\n",
      "torch.Size([8, 474]) torch.Size([8, 474])\n",
      "torch.Size([8, 374]) torch.Size([8, 374])\n",
      "torch.Size([8, 253]) torch.Size([8, 253])\n",
      "torch.Size([8, 189]) torch.Size([8, 189])\n",
      "torch.Size([8, 363]) torch.Size([8, 363])\n",
      "torch.Size([8, 516]) torch.Size([8, 516])\n",
      "torch.Size([8, 534]) torch.Size([8, 534])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 386]) torch.Size([8, 386])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 394]) torch.Size([8, 394])\n",
      "torch.Size([8, 244]) torch.Size([8, 244])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 678]) torch.Size([8, 678])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 223]) torch.Size([8, 223])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 454]) torch.Size([8, 454])\n",
      "torch.Size([8, 298]) torch.Size([8, 298])\n",
      "torch.Size([8, 278]) torch.Size([8, 278])\n",
      "torch.Size([8, 286]) torch.Size([8, 286])\n",
      "torch.Size([8, 504]) torch.Size([8, 504])\n",
      "torch.Size([8, 269]) torch.Size([8, 269])\n",
      "torch.Size([8, 578]) torch.Size([8, 578])\n",
      "torch.Size([8, 299]) torch.Size([8, 299])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 326]) torch.Size([8, 326])\n",
      "torch.Size([8, 617]) torch.Size([8, 617])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 479]) torch.Size([8, 479])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 436]) torch.Size([8, 436])\n",
      "torch.Size([8, 412]) torch.Size([8, 412])\n",
      "torch.Size([8, 514]) torch.Size([8, 514])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 566]) torch.Size([8, 566])\n",
      "torch.Size([8, 450]) torch.Size([8, 450])\n",
      "torch.Size([8, 341]) torch.Size([8, 341])\n",
      "torch.Size([8, 584]) torch.Size([8, 584])\n",
      "torch.Size([8, 291]) torch.Size([8, 291])\n",
      "torch.Size([8, 499]) torch.Size([8, 499])\n",
      "torch.Size([8, 459]) torch.Size([8, 459])\n",
      "torch.Size([8, 561]) torch.Size([8, 561])\n",
      "torch.Size([8, 743]) torch.Size([8, 743])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 156]) torch.Size([8, 156])\n",
      "torch.Size([8, 242]) torch.Size([8, 242])\n",
      "torch.Size([8, 671]) torch.Size([8, 671])\n",
      "torch.Size([8, 805]) torch.Size([8, 805])\n",
      "torch.Size([8, 364]) torch.Size([8, 364])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 577]) torch.Size([8, 577])\n",
      "torch.Size([8, 312]) torch.Size([8, 312])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 302]) torch.Size([8, 302])\n",
      "torch.Size([8, 432]) torch.Size([8, 432])\n",
      "torch.Size([8, 246]) torch.Size([8, 246])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 263]) torch.Size([8, 263])\n",
      "torch.Size([8, 343]) torch.Size([8, 343])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 417]) torch.Size([8, 417])\n",
      "torch.Size([8, 335]) torch.Size([8, 335])\n",
      "torch.Size([8, 175]) torch.Size([8, 175])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 362]) torch.Size([8, 362])\n",
      "torch.Size([8, 500]) torch.Size([8, 500])\n",
      "torch.Size([8, 294]) torch.Size([8, 294])\n",
      "torch.Size([8, 234]) torch.Size([8, 234])\n",
      "torch.Size([8, 358]) torch.Size([8, 358])\n",
      "torch.Size([8, 613]) torch.Size([8, 613])\n",
      "torch.Size([8, 337]) torch.Size([8, 337])\n",
      "torch.Size([8, 712]) torch.Size([8, 712])\n",
      "torch.Size([8, 280]) torch.Size([8, 280])\n",
      "torch.Size([8, 340]) torch.Size([8, 340])\n",
      "torch.Size([8, 1024]) torch.Size([8, 1024])\n",
      "torch.Size([8, 182]) torch.Size([8, 182])\n",
      "torch.Size([8, 296]) torch.Size([8, 296])\n",
      "torch.Size([8, 366]) torch.Size([8, 366])\n",
      "torch.Size([8, 268]) torch.Size([8, 268])\n",
      "torch.Size([8, 381]) torch.Size([8, 381])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 325]) torch.Size([8, 325])\n",
      "torch.Size([8, 468]) torch.Size([8, 468])\n",
      "torch.Size([8, 464]) torch.Size([8, 464])\n",
      "torch.Size([8, 314]) torch.Size([8, 314])\n",
      "torch.Size([8, 488]) torch.Size([8, 488])\n",
      "torch.Size([8, 354]) torch.Size([8, 354])\n",
      "torch.Size([8, 503]) torch.Size([8, 503])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 526]) torch.Size([8, 526])\n",
      "torch.Size([8, 275]) torch.Size([8, 275])\n",
      "torch.Size([8, 292]) torch.Size([8, 292])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 252]) torch.Size([8, 252])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 336]) torch.Size([8, 336])\n",
      "torch.Size([8, 390]) torch.Size([8, 390])\n",
      "torch.Size([8, 273]) torch.Size([8, 273])\n",
      "torch.Size([8, 504]) torch.Size([8, 504])\n",
      "torch.Size([8, 250]) torch.Size([8, 250])\n",
      "torch.Size([8, 204]) torch.Size([8, 204])\n",
      "torch.Size([8, 333]) torch.Size([8, 333])\n",
      "torch.Size([8, 405]) torch.Size([8, 405])\n",
      "torch.Size([8, 267]) torch.Size([8, 267])\n",
      "torch.Size([8, 404]) torch.Size([8, 404])\n",
      "torch.Size([8, 356]) torch.Size([8, 356])\n",
      "torch.Size([8, 266]) torch.Size([8, 266])\n",
      "torch.Size([8, 304]) torch.Size([8, 304])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 379]) torch.Size([8, 379])\n",
      "torch.Size([8, 501]) torch.Size([8, 501])\n",
      "torch.Size([8, 330]) torch.Size([8, 330])\n",
      "torch.Size([8, 869]) torch.Size([8, 869])\n",
      "torch.Size([8, 225]) torch.Size([8, 225])\n",
      "torch.Size([8, 412]) torch.Size([8, 412])\n",
      "torch.Size([8, 310]) torch.Size([8, 310])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 188]) torch.Size([8, 188])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 284]) torch.Size([8, 284])\n",
      "torch.Size([8, 287]) torch.Size([8, 287])\n",
      "torch.Size([8, 347]) torch.Size([8, 347])\n",
      "torch.Size([8, 369]) torch.Size([8, 369])\n",
      "torch.Size([8, 230]) torch.Size([8, 230])\n",
      "torch.Size([8, 474]) torch.Size([8, 474])\n",
      "torch.Size([8, 339]) torch.Size([8, 339])\n",
      "torch.Size([8, 448]) torch.Size([8, 448])\n",
      "torch.Size([8, 358]) torch.Size([8, 358])\n",
      "torch.Size([8, 645]) torch.Size([8, 645])\n",
      "torch.Size([8, 419]) torch.Size([8, 419])\n",
      "torch.Size([8, 295]) torch.Size([8, 295])\n",
      "torch.Size([8, 360]) torch.Size([8, 360])\n",
      "torch.Size([8, 282]) torch.Size([8, 282])\n",
      "torch.Size([8, 535]) torch.Size([8, 535])\n",
      "torch.Size([8, 612]) torch.Size([8, 612])\n",
      "torch.Size([8, 357]) torch.Size([8, 357])\n",
      "torch.Size([8, 503]) torch.Size([8, 503])\n",
      "torch.Size([8, 408]) torch.Size([8, 408])\n",
      "torch.Size([8, 498]) torch.Size([8, 498])\n",
      "torch.Size([8, 229]) torch.Size([8, 229])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 747]) torch.Size([8, 747])\n",
      "torch.Size([8, 207]) torch.Size([8, 207])\n",
      "torch.Size([8, 393]) torch.Size([8, 393])\n",
      "torch.Size([8, 274]) torch.Size([8, 274])\n",
      "torch.Size([8, 301]) torch.Size([8, 301])\n",
      "torch.Size([8, 211]) torch.Size([8, 211])\n",
      "torch.Size([8, 208]) torch.Size([8, 208])\n",
      "torch.Size([8, 327]) torch.Size([8, 327])\n",
      "torch.Size([8, 316]) torch.Size([8, 316])\n",
      "torch.Size([8, 240]) torch.Size([8, 240])\n",
      "torch.Size([8, 281]) torch.Size([8, 281])\n",
      "torch.Size([8, 559]) torch.Size([8, 559])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 179]) torch.Size([8, 179])\n",
      "torch.Size([8, 459]) torch.Size([8, 459])\n",
      "torch.Size([8, 262]) torch.Size([8, 262])\n",
      "torch.Size([8, 212]) torch.Size([8, 212])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 183]) torch.Size([8, 183])\n",
      "torch.Size([8, 186]) torch.Size([8, 186])\n",
      "torch.Size([8, 329]) torch.Size([8, 329])\n",
      "torch.Size([8, 385]) torch.Size([8, 385])\n",
      "torch.Size([8, 404]) torch.Size([8, 404])\n",
      "torch.Size([8, 236]) torch.Size([8, 236])\n",
      "torch.Size([8, 308]) torch.Size([8, 308])\n",
      "torch.Size([8, 321]) torch.Size([8, 321])\n",
      "torch.Size([8, 271]) torch.Size([8, 271])\n",
      "torch.Size([8, 209]) torch.Size([8, 209])\n",
      "torch.Size([8, 349]) torch.Size([8, 349])\n",
      "torch.Size([8, 290]) torch.Size([8, 290])\n",
      "torch.Size([8, 199]) torch.Size([8, 199])\n",
      "torch.Size([8, 222]) torch.Size([8, 222])\n",
      "torch.Size([8, 498]) torch.Size([8, 498])\n",
      "torch.Size([8, 397]) torch.Size([8, 397])\n",
      "torch.Size([8, 526]) torch.Size([8, 526])\n",
      "torch.Size([8, 332]) torch.Size([8, 332])\n",
      "torch.Size([8, 386]) torch.Size([8, 386])\n",
      "torch.Size([8, 153]) torch.Size([8, 153])\n",
      "torch.Size([8, 227]) torch.Size([8, 227])\n",
      "torch.Size([8, 258]) torch.Size([8, 258])\n",
      "torch.Size([8, 239]) torch.Size([8, 239])\n",
      "torch.Size([8, 261]) torch.Size([8, 261])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 685]) torch.Size([8, 685])\n",
      "torch.Size([8, 276]) torch.Size([8, 276])\n",
      "torch.Size([8, 243]) torch.Size([8, 243])\n",
      "torch.Size([8, 164]) torch.Size([8, 164])\n",
      "torch.Size([8, 437]) torch.Size([8, 437])\n",
      "torch.Size([8, 248]) torch.Size([8, 248])\n",
      "torch.Size([8, 380]) torch.Size([8, 380])\n",
      "torch.Size([8, 805]) torch.Size([8, 805])\n",
      "torch.Size([8, 279]) torch.Size([8, 279])\n",
      "torch.Size([8, 495]) torch.Size([8, 495])\n",
      "torch.Size([8, 206]) torch.Size([8, 206])\n",
      "torch.Size([8, 1013]) torch.Size([8, 1013])\n",
      "torch.Size([8, 320]) torch.Size([8, 320])\n",
      "torch.Size([8, 168]) torch.Size([8, 168])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ce26c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26ff198c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n",
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\encoder.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\hparams.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.data-00000-of-00001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\model.ckpt.meta\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'openaipublic.blob.core.windows.net'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\355M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "#Now it is time to load pre-trainned llm model\n",
    "from Fundamentals.gpt_download import download_and_load_gpt2\n",
    "from Foundational.utils.model import GPT_Model\n",
    "from Foundational.utils.loadwt_into_gpt import load_weights_into_gpt\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size,\n",
    "    models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPT_Model(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b5482be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Foundational.utils.generate import generate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76b68c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Reword the following sentence to the future tense.\n",
      "\n",
      "### Input:\n",
      "He is reading a novel inspired by his grandmother.\n",
      "The primary function of the human heart is to pump blood throughout the body, delivering oxygen and nutrients to tissues and removing carbon dioxide and other wastes.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "input_text = format_input(validate_data[1])\n",
    "print(input_text)\n",
    "print(validate_data[0]['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55dedf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tiktoken\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    print(flat)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "# start_context = \"Every effort moves you\"\n",
    "# tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# token_ids = generate_text_simple(\n",
    "#     model=model,\n",
    "#     idx=text_to_token_ids(start_context, tokenizer),\n",
    "#     max_new_tokens=10,\n",
    "#     context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    "# )\n",
    "\n",
    "# print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40f6fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,   585,   262,  1708,  6827,   284,\n",
      "          262,  2003, 20170,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "         1544,   318,  3555,   257,  5337,  7867,   416,   465, 18410,    13,\n",
      "          198,   198, 21017, 25235,    25,   198,   198,  1544,   318,  3555,\n",
      "          257,  5337,  7867,   416,   465, 18410,    13,   198,   198, 21017,\n",
      "        46486,    25,   198,   198, 16594,   257,  2882,   326, 20431, 32543,\n",
      "          262,  2581,    13,   198,   198])\n"
     ]
    }
   ],
   "source": [
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(input_text, tokenizer),\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36804f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Output:\n",
      "\n",
      "He is reading a novel inspired by his grandmother.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Write a response that appropriately completes the request.\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text):].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c93dca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we see the ouput is not good and accurate that why we cant depend on pretrainned model \n",
    "# now we will train the model with our own data to make the accuracy high \n",
    "#lets check loss of this pretrainned model\n",
    "from Foundational.utils.calc_loader_loss import calc_loader_loss\n",
    "from Foundational.utils.calc_loader_loss import calc_batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1fd89035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loader_loss(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loader_loss(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fd12022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.8279, device='cuda:0') tensor(2.8338, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loader_loss(train_loader, device=device, model=model)\n",
    "    val_loss = calc_loader_loss(val_loader,device=device,model=model)\n",
    "\n",
    "print(train_loss,val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd752f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a15c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre trainning the llm model \n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_batch_loss(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel() # Returns the total number of elements (or tokens) in the input_batch.\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0: \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "        # torch.save({\n",
    "        #     \"model_state_dict\": model.state_dict(),\n",
    "        #     \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        #     }, \n",
    "        #     \"model_and_optimizer.pth\"\n",
    "        #         )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5204cbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b416a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb72b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_25460\\2008901580.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('checkpoint_epoch1.pth', map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.483, Val loss 0.707\n",
      "Ep 1 (Step 000005): Train loss 0.436, Val loss 0.709\n",
      "Ep 1 (Step 000010): Train loss 0.344, Val loss 0.716\n",
      "Ep 1 (Step 000015): Train loss 0.364, Val loss 0.716\n",
      "Ep 1 (Step 000020): Train loss 0.430, Val loss 0.722\n",
      "Ep 1 (Step 000025): Train loss 0.396, Val loss 0.715\n",
      "Ep 1 (Step 000030): Train loss 0.424, Val loss 0.715\n",
      "Ep 1 (Step 000035): Train loss 0.407, Val loss 0.711\n",
      "Ep 1 (Step 000040): Train loss 0.347, Val loss 0.705\n",
      "Ep 1 (Step 000045): Train loss 0.392, Val loss 0.702\n",
      "Ep 1 (Step 000050): Train loss 0.353, Val loss 0.710\n",
      "Ep 1 (Step 000055): Train loss 0.368, Val loss 0.729\n",
      "Ep 1 (Step 000060): Train loss 0.349, Val loss 0.729\n",
      "Ep 1 (Step 000065): Train loss 0.339, Val loss 0.729\n",
      "Ep 1 (Step 000070): Train loss 0.280, Val loss 0.734\n",
      "Ep 1 (Step 000075): Train loss 0.321, Val loss 0.714\n",
      "Ep 1 (Step 000080): Train loss 0.278, Val loss 0.712\n",
      "Ep 1 (Step 000085): Train loss 0.322, Val loss 0.716\n",
      "Ep 1 (Step 000090): Train loss 0.306, Val loss 0.723\n",
      "Ep 1 (Step 000095): Train loss 0.292, Val loss 0.729\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18438,   391,   262,  4165,  2163,   286,\n",
      "          262,  1692,  2612,    13,   198, 21017, 18261,    25,   198,   464,\n",
      "         4165,  2163,   286,   262,  1692,  2612,   318,   284,  8901,  2910,\n",
      "          284,   262,  3632,   290,   284,  5127,   340,   351, 20901,   290,\n",
      "        11863,    13,   632,   635,  5419,   284, 16697,  2910,  3833,   290,\n",
      "          284,  5127,   262,  1767,   351,  2568,    13,   198, 21017, 18261,\n",
      "           25,   198,   464,  4165], device='cuda:0')\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Explain the primary function of the human heart. ### Response: The primary function of the human heart is to pump blood to the brain and to supply it with nutrients and oxygen. It also helps to regulate blood pressure and to supply the body with energy. ### Response: The primary\n",
      "Training completed in 45.83 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "checkpoint = torch.load('checkpoint_epoch1.pth', map_location=device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "train_loss = checkpoint.get('train_loss', None)\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(validate_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "291b38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ba29290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and optimizer states\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'epoch': 2,   # your current epoch\n",
    "    'train_loss': train_loss\n",
    "}, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66915ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('checkpoint_epoch1.pth', map_location=device)\n",
    "\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# start_epoch = checkpoint['epoch'] + 1\n",
    "# train_loss = checkpoint.get('train_loss', None)\n",
    "\n",
    "# print(train_loss)\n",
    "# now this saves the parameters in the model and optimizer and later while doing finetunning we can resume from this saved state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94bd6835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 3\n",
    "\n",
    "# train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "#     model, train_loader, val_loader, optimizer, device,\n",
    "#     num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "#     start_context=format_input(validate_data[0]), tokenizer=tokenizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78b48aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 28873, 47625,   329,\n",
      "          705,    33, 19335,   286,  5800, 30960,   198, 21017, 18261,    25,\n",
      "          198,   464, 28873, 47625,   329,   705,    33, 19335,   286,  5800,\n",
      "            6,   318,   347,    13,  3351,    13], device='cuda:0')\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the abbreviation for 'Bachelor of Science'?\n",
      "\n",
      "Correct response:\n",
      ">> The abbreviation for 'Bachelor of Science' is B.Sc.\n",
      "\n",
      "Model response:\n",
      ">> The abbreviation for 'Bachelor of Science' is B.Sc.\n",
      "-------------------------------------\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,  1542, 48829,   284, 10700,\n",
      "           13,   198, 21017, 18261,    25,   198,  1270, 48829,   318, 20343,\n",
      "        10700,    13], device='cuda:0')\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert 30 centimeters to meters.\n",
      "\n",
      "Correct response:\n",
      ">> 30 centimeters is 0.3 meters.\n",
      "\n",
      "Model response:\n",
      ">> 30 centimeters is 3000 meters.\n",
      "-------------------------------------\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24372,   966,   286,\n",
      "        43142,   287, 34186,    30,   198, 21017, 18261,    25,   198,   464,\n",
      "        24372,   966,   286, 43142,   318,  6702,  8699,  7370, 34186,    13],\n",
      "       device='cuda:0')\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What is the boiling point of helium in Celsius?\n",
      "\n",
      "Correct response:\n",
      ">> The boiling point of helium is -268.9 degrees Celsius.\n",
      "\n",
      "Model response:\n",
      ">> The boiling point of helium is approximately 78 degrees Celsius.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text):]\n",
    "        .replace(\"### Response:\", \"\")\n",
    "        .strip()\n",
    ")\n",
    "\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184e1b9",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef6f0a8",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "Most importantly, we can see that model evaluation is not as straightforward as in the\n",
    "previous chapter, where we simply calculated the percentage of correct spam/non-spam\n",
    "class labels to obtain the classification accuracy. \n",
    "\n",
    "In practice, instruction-finetuned LLMs\n",
    "such as chatbots are evaluated via multiple approaches:\n",
    "\n",
    "1. Short-answer and multiple choice benchmarks such as MMLU (\"Measuring\n",
    "Massive Multitask Language Understanding,\" https://arxiv.org/abs/2009.\n",
    "03300), which test the general knowledge of a model.\n",
    "\n",
    "2. Human preference comparison to other LLMs, such as LMSYS chatbot\n",
    "arena (https://arena.lmsys.org).\n",
    "\n",
    "3. Automated conversational benchmarks, where another LLM like GPT-4 is\n",
    "used to evaluate the responses, such as AlpacaEval (https://tatsulab.github.io/alpaca_eval/).\n",
    "completes the request.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a63e7d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/220 [00:01<06:00,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 28873, 47625,   329,\n",
      "          705,    33, 19335,   286,  5800, 30960,   198, 21017, 18261,    25,\n",
      "          198,   464, 28873, 47625,   329,   705,    33, 19335,   286,  5800,\n",
      "            6,   318,   347,    13,  3351,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/220 [00:02<04:28,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,  1542, 48829,   284, 10700,\n",
      "           13,   198, 21017, 18261,    25,   198,  1270, 48829,   318, 20343,\n",
      "        10700,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 3/220 [00:03<04:39,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24372,   966,   286,\n",
      "        43142,   287, 34186,    30,   198, 21017, 18261,    25,   198,   464,\n",
      "        24372,   966,   286, 43142,   318,  6702,  8699,  7370, 34186,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 4/220 [00:05<04:29,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   362,  6578,   364,   284,\n",
      "         3939,  6392,   364,    13,   198, 21017, 18261,    25,   198,    17,\n",
      "         6578,   364,   318, 20343,  3939,  6392,   364,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 5/220 [00:06<04:11,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 41762,   262,  1708,  6827,   284,  2291,\n",
      "          281,   409, 20931,  1317,   284,   905, 14067,    13,   198,   198,\n",
      "        21017, 23412,    25,   198,    40,  1839,   262, 22098,     0,   198,\n",
      "        21017, 18261,    25,   198,    40,  1839,   262, 22098,     0],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 6/220 [00:07<04:15,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "          779,   257,   985,   576,    25,   383,  2344,   703,   992,   832,\n",
      "          262,  1755,    13,   198,   198, 21017, 18261,    25,   198,   464,\n",
      "         2344,   703,   992,   832,   262,  1755,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 7/220 [00:08<04:24,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 22918,  1988,   286,\n",
      "         5899,  1660,   379,  1679,  7200,    34,    30,   198, 21017, 18261,\n",
      "           25,   198,   464, 22918,  1988,   286,  5899,  1660,   318,   767,\n",
      "           13,    20,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 8/220 [00:10<04:26,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3163,  9521,   777,  6754,  9574,   287,\n",
      "        45946,  1502,    25,  6046, 21449,    11, 29396,    11, 19034,  9303,\n",
      "           13,   198, 21017, 18261,    25,   198, 34621, 21449,   198,    49,\n",
      "         8107, 16419,   198, 35848,  4454,  9303], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 9/220 [00:10<03:42,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 16742,   257,  6171,  5177,   329,   262,\n",
      "         1573,   705,  9688,  4458,   198,   198, 21017, 18261,    25,   198,\n",
      "        10434], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 10/220 [00:15<07:22,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262,  4165,  7577,   287,\n",
      "          262, 25228,  3124,  2746,    13,   198, 20560,    25,   198,   464,\n",
      "         4165,  7577,   287,   262, 25228,  3124,  2746,   389,  2266,    11,\n",
      "         4077,    11,   290,  4171,    13,   198, 26410,    25,   198,   464,\n",
      "         4165,  7577,   287,   262, 25228,  3124,  2746,   389,  2266,    11,\n",
      "         4077,    11,   290,  4171,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 11/220 [00:17<08:05,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,  1115,  3858,   286, 15114,    13,\n",
      "          198, 21017, 18261,    25,   198,    16,    13, 10130,   198,    17,\n",
      "           13, 33381,   198,    18,    13,  3825,   198, 21017, 18261,    25,\n",
      "          198,    16,    13, 10130,   198,    17,    13, 33381,   198,    18,\n",
      "           13,  3825], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 12/220 [00:20<08:18,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262,  8216,   973,   287,\n",
      "          262, 21247,   705,   464,  5567,  1892, 30222,     6,   416,  5199,\n",
      "        15122,    13,   198,   198, 21017, 18261,    25,   198,   464,  8216,\n",
      "          973,   287,   262, 21247,   705,   464,  5567,  1892, 30222,     6,\n",
      "          318,   257,  3105,    11, 47886, 14009,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 13/220 [00:21<06:50,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 19400,   428,  6827,   656,   262,  1613,\n",
      "         2818, 12948, 20170,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "         3347, 33041,   287,   262, 42644,    13,   198, 21017, 18261,    25,\n",
      "          198,  3347, 33041,   287,   262, 42644,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|         | 14/220 [00:22<05:31,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705, 19276,  7609,  4458,   198,   198, 21017, 18261,    25,\n",
      "          198, 30946,  7609,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 15/220 [00:23<05:03,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705,    66, 16421,  4458,   198,   198, 21017, 18261,    25,\n",
      "          198,    34, 16421,   546,   644,   318,  1016,   319,    30],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 16/220 [00:24<05:04,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24372,   966,   286,\n",
      "          275,   398,   500,   287, 34186,    30,   198, 21017, 18261,    25,\n",
      "          198,   464, 24372,   966,   286,   275,   398,   500,   318,  6702,\n",
      "         8699,  7370, 34186,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 17/220 [00:26<05:21,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  9546,   656,   257,\n",
      "         1844,  6827,    13,   198,   198, 21017, 23412,    25,   198, 19155,\n",
      "         2617,   625,   262,  9151,   198, 21017, 18261,    25,   198,   464,\n",
      "         9546,   366, 19155,  2617,   625,   262,  9151,     1,   318,   257,\n",
      "         1844,  6827,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 18/220 [00:27<04:43,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "        23094,    13,   198,   198, 21017, 23412,    25,   198,   464,  2119,\n",
      "          373,   845,  1402,    13,   198, 21017, 18261,    25,   198,   464,\n",
      "         2119,   373,   845,  1402,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 19/220 [00:33<09:21,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3163,  9521,   262,  1708,  2995,   287,\n",
      "        45946,  1502,    25,  3274,  6869, 29689,    11,  4141,  9303,    11,\n",
      "        19034,  9303,    13,   198, 21017, 18261,    25,   198,   464,  4141,\n",
      "         9303,   373,   262,  1255,   286,   262,  4141,  9303,    11,   543,\n",
      "          373,  2957,   416,   262,  4141,  9303,  3166,    13,   383, 19034,\n",
      "         9303,   373,   262,  1255,   286,   262, 19034,  9303,    11,   543,\n",
      "          373,  2957,   416,   262, 19034,  9303,   364,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|         | 20/220 [00:35<07:57,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  3139,   286,   262,\n",
      "         1578,  1829,    30,   198, 21017, 18261,    25,   198,   464,  3139,\n",
      "          286,   262,  1578,  1829,   318,  2669,   360,    13,    34,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 21/220 [00:47<17:22,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 24564,  4892,   262,  1388,  2163,   286,\n",
      "          262,  1692, 30142,  1080,    13,   198, 21017, 18261,    25,   198,\n",
      "          464,  1388,  2163,   286,   262,  1692, 30142,  1080,   318,   284,\n",
      "         1104,   262,  1767,   416,  6493,   262,  2793,  1767,   290,  6493,\n",
      "          262,  6727,  1767,    13,   632,  3407,   262, 19656,    11,   300,\n",
      "         2178,   283,    11,   290,  2793,  8963,   871,    13,   198, 21017,\n",
      "        18261,    25,   198,   464,  1388,  2163,   286,   262,  1692, 30142,\n",
      "         1080,   318,   284,  1104,   262,  1767,   416,  6493,   262,  2793,\n",
      "         1767,   290,  6493,   262,  6727,  1767,    13,   632,  3407,   262,\n",
      "        19656,    11,   300,  2178,   283,    11,   290,  2793,  8963,   871,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 22/220 [00:48<13:03,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262, 20170,   973,   287,\n",
      "          262,  6827,    13,   198,   198, 21017, 23412,    25,   198,  2990,\n",
      "          389,  4964,   257,  3807,    13,   198, 21017, 18261,    25,   198,\n",
      "         2990,   389,  4964,   257,  3807,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 23/220 [00:50<11:03,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 40716,   345,     6,\n",
      "          656,  2679,    13,   198, 21017, 18261,    25,   198,    35,   292,\n",
      "        23670,   318,    83,  1658,  1976,    84,   443,   312,    11,   288,\n",
      "          562,  1658,  1976,    84,   443,   312,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|         | 24/220 [00:52<10:01,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 43857,   257, 24659,   329,   262,  6827,\n",
      "           13,   198,   198, 21017, 23412,    25,   198,  3260,   262,  6290,\n",
      "         5025,    11,   262,  1751,  2826,   287,   262,  3952,    13,   198,\n",
      "        21017, 18261,    25,   198,  3260,   262,  6290,  5025,    11,   262,\n",
      "         1751,  2826,   287,   262,  3952,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|        | 25/220 [00:53<08:14,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 20884,   966,   286,\n",
      "         1660,   287, 35935,    30,   198, 21017, 18261,    25,   198,   464,\n",
      "        20884,   966,   286,  1660,   318,   657,  7370, 34186,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 26/220 [00:54<06:50,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,   326,  5679,\n",
      "          262,  3912,    25,   705,  9203,   645,  5917,   815,   345,   220,\n",
      "        29343,     6,   198, 21017, 18261,    25,   198,  9203,   645,  5917,\n",
      "          815,   345,   220, 29343,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 27/220 [00:57<07:02,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 22743,   262,  1708, 23491,  7457,    13,\n",
      "          198,   198, 21017, 23412,    25,   198,  1544,   765,   284,   467,\n",
      "          284,   262,  6918,    11,   475,   339,   468,   645,  1637,    13,\n",
      "          198,   198, 21017, 18261,    25,   198,  1544,   765,   284,   467,\n",
      "          284,   262,  6918,    11,   475,   339,   468,   645,  1637,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 28/220 [00:58<06:11,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   257,  6171,  5177,   329,\n",
      "          705, 36673, 30960,   198, 21017, 18261,    25,   198,    32,  6171,\n",
      "         5177,   329,   705, 36673,     6,   318,   705,  8940,  4458],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|        | 29/220 [00:59<05:23,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  2347,   422, 37075,\n",
      "          284, 16379,    13,   198,   198, 21017, 23412,    25,   198,    18,\n",
      "        37075,   198, 21017, 18261,    25,   198,    18, 37075,   318,  7548,\n",
      "          284,   513, 16379,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 30/220 [01:00<04:45,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  3139,   286, 19101,\n",
      "           30,   198, 21017, 18261,    25,   198,   464,  3139,   286, 19101,\n",
      "          318, 41898,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 31/220 [01:02<04:35,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,   257,  3623,  8811,  1043,   287,\n",
      "          262,  3668,   338,  8137,    13,   198, 20560,    25,   198,    32,\n",
      "         3623,  8811,  1043,   287,   262,  3668,   338,  8137,   318, 25006,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 32/220 [01:03<04:44,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 42758,   262,  1708,  3146,   287, 41988,\n",
      "         1502,    13,   198,   198, 21017, 23412,    25,   198,    20,    11,\n",
      "         1248,    11,   513,    11,  1367,    13,   198, 21017, 18261,    25,\n",
      "          198,    16,    11,   513,    11,  1105,    11,   513,    11,   513,\n",
      "           11,  1105,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 33/220 [01:04<04:04,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705, 22126,   421,   298,  4458,   198,   198, 21017, 18261,\n",
      "           25,   198,  9527, 22696,   298,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 34/220 [01:06<04:28,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   428,  6827,  1262,  5035,\n",
      "        23491,  3173,    25,   198,   198, 21017, 23412,    25,   198,   258,\n",
      "         2497,   257,  1468,   582,   287,   262,  3952,    13,   198,   198,\n",
      "        21017, 18261,    25,   198,  1544,  2497,   257,   582,   287,   262,\n",
      "         3952,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 35/220 [01:07<04:38,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   281,   281,  1122,  4948,\n",
      "          286,   705,  1102,   344,   282, 30960,   198, 21017, 18261,    25,\n",
      "          198,  2025,   281,  1122,  4948,   286,   705,  1102,   344,   282,\n",
      "            6,   318,   705, 36955,   282,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|        | 36/220 [01:09<04:35,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   523,\n",
      "          326,   340,   318,   287,  4075,  3809,    13,   198,   198, 21017,\n",
      "        23412,    25,   198,   464, 14746,   547, 17065,   416,   262,  1751,\n",
      "           13,   198,   198, 21017, 18261,    25,   198,   464, 14746,   547,\n",
      "        17065,   416,   262,  1751,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 37/220 [01:10<04:26,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24372,   966,   286,\n",
      "         1660,   287, 34186,    30,   198, 21017, 18261,    25,   198,   464,\n",
      "        24372,   966,   286,  1660,   318,  6702,  8699,  7370, 34186,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 38/220 [01:11<03:59,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705,    40,  1842,   345,\n",
      "            6,   656,  7897,    13,   198, 21017, 18261,    25,   198, 22362,\n",
      "        21162,  1658,  8957, 12654,   349,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 39/220 [01:12<03:46,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705,    40,   716,  3772,\n",
      "            6,   656,  4141,    13,   198, 21017, 18261,    25,   198, 14772,\n",
      "          410,   494,  1556,   443,   285, 14378,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|        | 40/220 [01:14<04:29,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   281,   281,  1122,  4948,\n",
      "          329,   262,  1573,   705, 40085,  2569,  4458,   198, 21017, 18261,\n",
      "           25,   198,  2025,   281,  1122,  4948,   329,   262,  1573,   705,\n",
      "        40085,  2569,     6,   714,   307,   705, 40085,  2569, 32277,   396,\n",
      "         4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 41/220 [01:18<06:00,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "        23094,    13,   198,   198, 21017, 23412,    25,   198,  9360,  8212,\n",
      "          318,   845,  6016,    13,   198, 21017, 18261,    25,   198,  9360,\n",
      "         8212,   318,   355,  6016,   355,   262,  4252,    13,   198, 21017,\n",
      "        18261,    25,   198,  9360,  8212,   318,   355,  6016,   355,   262,\n",
      "         4252,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|        | 42/220 [01:18<04:47,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15946,   485,   257,  6171,  5177,   329,\n",
      "          705, 40544,  4135,  4458,   198, 21017, 18261,    25,   198, 38413,\n",
      "         4135,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 43/220 [03:21<1:51:36, 37.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705, 24729,\n",
      "        44411,  4458,   198, 21017, 18261,    25,   198, 21197, 44411,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656,  5931,  2568,\n",
      "          416,  6134,    13,   632,   318,   262,  1429,   416,   543, 19606,\n",
      "          318, 11513,   656,  5931,  2568,   416,  6134,    13,   632,   318,\n",
      "          262,  1429,   416,   543, 19606,   318, 11513,   656],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 44/220 [03:28<1:23:38, 28.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3163,  9521,   262,  1708,  2995,   287,\n",
      "        45946,  1502,    25, 49110,   286,   262, 19401,    11,  7218,   286,\n",
      "          262, 11307,  5007,    11, 23455,   286,  2253,    13,   198, 21017,\n",
      "        18261,    25,   198,   464, 14250,   286,   262, 19401,   373,  5071,\n",
      "          416,   262,  2679,  8022,    11, 25028,    77, 50182, 12381,    11,\n",
      "          287, 36094,    13,   383,  2121,   286,   262, 11307,  5007,   373,\n",
      "         5071,   416,   262,  1578,  1829,  1230,   287, 24217,    13,   383,\n",
      "         9412,   286,  2253,   373,  5071,   416,   262,  1578,  1829,  1230,\n",
      "          287,  1596,  4304,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 45/220 [03:34<1:03:38, 21.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,    35,  2357,  3810,   262, 29973,  2700,\n",
      "         7205,   319,   281,  2134,   351,   257,  2347,   286,   838, 14211,\n",
      "          319,  3668,    13,   198, 20560,    25,   198,   464, 29973,  2700,\n",
      "         7205,   319,   262,  2134,   351,   257,  2347,   286,   838, 14211,\n",
      "          318,  6702,   657,    13,    20,   308,    13,   198, 21017, 18261,\n",
      "           25,   198,   464, 29973,  2700,  7205,   319,   262,  2134,   351,\n",
      "          257,  2347,   286,   838, 14211,   318,  6702,   657,    13,    20,\n",
      "          308,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|        | 46/220 [03:35<45:25, 15.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 43857,   257, 24659,   329,   262,  6827,\n",
      "           13,   198,   198, 21017, 23412,    25,   198,  2215,   262,  4252,\n",
      "          900,    11,   314,  1816,   284,  3993,    13,   198, 21017, 18261,\n",
      "           25,   198,    40,  1816,   284,  3993,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|       | 47/220 [05:48<2:27:01, 50.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,    35,  2357,  3810,  1771,   262,  1813,\n",
      "          734,  2456,   389,  6171, 43612,   393,   281,  1122,    88,   907,\n",
      "           13,   198,   198, 21017, 23412,    25,   198, 11505,   532, 13872,\n",
      "          198,  2025,  1122,    88,   907,    25,   198, 29934, 43612,    25,\n",
      "          198, 26125,   532,  4946,   198, 21017, 18261,    25,   198, 29934,\n",
      "        43612,    25,  4946,   198,  2025,  1122,    88,   907,    25, 13872,\n",
      "          198, 21017, 18261,    25,   198, 29934, 43612,    25,  4946,   198,\n",
      "         2025,  1122,    88,   907,    25, 13872,   198, 21017, 18261,    25,\n",
      "          198, 29934, 43612,    25,  4946,   198,  2025,  1122,    88,   907,\n",
      "           25, 13872,   198, 21017, 18261,    25,   198, 29934, 43612,    25,\n",
      "         4946,   198,  2025,  1122,    88,   907,    25, 13872,   198, 21017,\n",
      "        18261,    25,   198, 29934, 43612,    25,  4946,   198,  2025,  1122,\n",
      "           88,   907,    25, 13872,   198, 21017, 18261,    25,   198, 29934,\n",
      "        43612,    25,  4946,   198,  2025,  1122,    88,   907,    25, 13872,\n",
      "          198, 21017, 18261,    25,   198, 29934, 43612,    25,  4946,   198,\n",
      "         2025,  1122,    88,   907,    25, 13872,   198, 21017, 18261,    25,\n",
      "          198, 29934, 43612,    25,  4946,   198,  2025,  1122,    88,   907,\n",
      "           25, 13872,   198, 21017, 18261,    25,   198, 29934, 43612,    25,\n",
      "         4946,   198,  2025,  1122,    88,   907,    25, 13872,   198, 21017,\n",
      "        18261,    25,   198, 29934, 43612,    25,  4946,   198,  2025,  1122,\n",
      "           88,   907,    25, 13872,   198, 21017, 18261,    25,   198, 29934,\n",
      "        43612,    25,  4946,   198,  2025,  1122,    88,   907,    25, 13872,\n",
      "          198, 21017, 18261,    25,   198, 29934, 43612,    25,  4946,   198,\n",
      "         2025,  1122,    88,   907,    25, 13872,   198, 21017, 18261,    25,\n",
      "          198, 29934, 43612,    25,  4946,   198,  2025,  1122,    88,   907,\n",
      "           25, 13872,   198, 21017, 18261,    25,   198, 29934, 43612,    25,\n",
      "         4946,   198,  2025,  1122,    88,   907,    25, 13872,   198, 21017,\n",
      "        18261,    25,   198, 29934, 43612,    25,  4946,   198,  2025,  1122,\n",
      "           88,   907,    25, 13872,   198, 21017], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 48/220 [05:50<1:43:29, 36.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "         4781, 49052,    13,   198,   198, 21017, 23412,    25,   198,  3347,\n",
      "          925,   257,  4506, 10638,   286,   262,  1492,    13,   198, 21017,\n",
      "        18261,    25,   198,  3347,   925,   257,  4506, 10638,   286,   262,\n",
      "         1492,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|       | 49/220 [05:52<1:14:13, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9771,  3129,   378,   262,  1989,   286,\n",
      "          257, 22950,   351,   257,  2779,   286,   838,  4991,   290,  6001,\n",
      "          286,   642,  4991,    13,   198, 20560,    25,   198,   464,  1989,\n",
      "          286,   262, 22950,   318,   838,    13,   198, 26410,    25,   198,\n",
      "          464,  1989,   286,   262, 22950,   318,   642,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 50/220 [05:54<52:59, 18.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15946,   485,   257,  6171,  5177,   329,\n",
      "          705, 12543,  3281,  4458,   198, 21017, 18261,    25,   198,    32,\n",
      "         6171,  5177,   329,   705, 12543,  3281,     6,   318,   705,    82,\n",
      "          324,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 51/220 [05:56<38:27, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262,  7505,   286,   262,\n",
      "         1621,    13,   198,   198, 21017, 23412,    25,   198,   464, 28467,\n",
      "        25678,   290,   262, 42285,   198, 21017, 18261,    25,   198,   464,\n",
      "         7505,   286,   262,  1621,   318,   366,   464, 28467, 25678,   290,\n",
      "          262, 42285,   526], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 52/220 [06:02<32:19, 11.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3163,  9521,   777,  6754,  9574,   287,\n",
      "        45946,  1502,    25, 29396,    11,  7993,  8065,    11, 24569, 25466,\n",
      "           13,   198, 21017, 18261,    25,   198,   464, 29396,   373,   262,\n",
      "         2278,   422,   262,  1315,   400,  4289,   284,   262,   678,   400,\n",
      "         4289,    13,   383,  7993,  8065,   373,   262,  2278,   422,   262,\n",
      "          352,   301,  4289,   284,   262,   513,  4372,  4289,    13,   383,\n",
      "        24569, 25466,   373,   262,  2278,   422,   262,  1248,   400,  4289,\n",
      "          284,   262,  1160,   400,  4289,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 53/220 [06:04<23:41,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  1708,  6827,   284,\n",
      "          779,   257,  3585, 13444,    25,   383,   582,   318,   257,  4701,\n",
      "           13,   679,  3160,  1306,  3420,    13,   198, 31077,    25,   198,\n",
      "          464,   582,   318,   257,  4701,    13,   679,  3160,  1306,  3420,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 54/220 [06:07<18:41,  6.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,   257, 24603,  5440,   287,   674,\n",
      "         6591,  1080,    13,   198, 20560,    25,   198,    35,  5767,    69,\n",
      "        11397,    25, 21673,   198, 26410,    25,   198,    32, 24603,  5440,\n",
      "          318,   257,  5440,   326,   318,  4833,   621,  3668,   290, 37015,\n",
      "          262,  4252,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 55/220 [06:08<14:08,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   281,\n",
      "         4686, 29005,    13,   198,   198, 21017, 23412,    25,   198,  1544,\n",
      "          318,   845, 14431,    13,   679,  1464,  5419,  1854,    13,   198,\n",
      "        21017, 18261,    25,   198,  1544,  1464,  5419,  1854,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|       | 56/220 [06:10<11:09,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   257,  6171,  5177,   286,\n",
      "          705,    65,  5758, 30960,   198, 21017, 18261,    25,   198,    32,\n",
      "         6171,  5177,   329,   705,    65,  5758,     6,   318,   705,  8232,\n",
      "          446,   306,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 57/220 [06:11<08:40,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,  1802,  8059,   284, 37075,\n",
      "           13,   198, 21017, 18261,    25,   198,  3064,  8059,   318,   657,\n",
      "           13,   405, 37075,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|       | 58/220 [06:12<06:53,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "        23094,    13,   198,   198, 21017, 23412,    25,   198,   464,  4252,\n",
      "          373, 22751, 35254,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  4252,   373, 22751, 35254,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 59/220 [06:14<06:23,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262, 43441,   287,   262,\n",
      "         6827,    13,   198,   198, 21017, 23412,    25,   198,   464,  2068,\n",
      "        21831, 11687,   625,   262, 16931,  3290,    13,   198, 21017, 18261,\n",
      "           25,   198,   464, 43441,   287,   262,  6827,   318,   366,    73,\n",
      "        27073,   625,   262, 16931,  3290,   526], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 60/220 [06:15<05:30,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15946,   485,   257,  6171,  5177,   329,\n",
      "          705, 11576,  4458,   198, 21017, 18261,    25,   198, 33004,  6171,\n",
      "         5177,   329,   705, 11576,     6,   318,   705, 11576,  4458],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 61/220 [08:29<1:49:59, 41.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  1808,   351,   262,\n",
      "        21179,   705,    85, 19397,     6,   287,   262,  2426,  1627,    13,\n",
      "          198, 21017, 18261,    25,   198,    53, 19397,   318,   257,  2099,\n",
      "          286, 11492,   326,  5640,  4168, 35258,    13,   632,   460,   307,\n",
      "         4104,   416,  1277,  2800,   351,   262,  4168,    11,   832,   262,\n",
      "        22949,  1080,    11,   393,   832,  2800,   351, 23543,  9528,   393,\n",
      "         5563,    13,   198, 21017,  7735, 27759,    25,   198,  2061,  2099,\n",
      "          286, 11492,   318,   262,   705,    85, 19397, 30960,   198,  2061,\n",
      "         2099,   286,  9528,   318, 23543,    30,   198,  2061,  2099,   286,\n",
      "         2134,   318, 23543,    30,   198, 21017, 18261,    25,   198,   464,\n",
      "          705,    85, 19397,     6,   318,   257,  2099,   286, 11492,   326,\n",
      "         5640,  4168, 35258,    13,   632,   460,   307,  4104,   416,  1277,\n",
      "         2800,   351,   262,  4168,    11,   832,   262, 22949,  1080,    11,\n",
      "          393,   832,  2800,   351, 23543,  9528,   393,  5563,    13,   198,\n",
      "        21017,  7735, 27759,    25,   198,  2061,  2099,   286, 11492,   318,\n",
      "          262,   705,    85, 19397, 30960,   198,  2061,  2099,   286,  9528,\n",
      "          318, 23543,    30,   198,  2061,  2099,   286,  2134,   318, 23543,\n",
      "           30,   198, 21017, 18261,    25,   198,   464,   705,    85, 19397,\n",
      "            6,   318,   257,  2099,   286, 11492,   326,  5640,  4168, 35258,\n",
      "           13,   632,   460,   307,  4104,   416,  1277,  2800,   351,   262,\n",
      "         4168,    11,   832,   262, 22949,  1080,    11,   393,   832,  2800,\n",
      "          351, 23543,  9528,   393,  5563,    13,   198, 21017,  7735, 27759,\n",
      "           25,   198,  2061,  2099,   286, 11492,   318,   262,   705,    85,\n",
      "        19397, 30960,   198,  2061,  2099,   286,  9528,   318, 23543,    30,\n",
      "          198,  2061,  2099,   286,  2134,   318, 23543,    30,   198, 21017,\n",
      "        18261,    25,   198,   464,   705,    85, 19397,     6,   318,   257,\n",
      "         2099,   286, 11492,   326,  5640,  4168, 35258,    13,   632,   460,\n",
      "          307], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|       | 62/220 [08:30<1:17:29, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,  1262,\n",
      "        14513,  3809,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         1074,  8793,  1049,  2482,    13,   198,   198, 21017, 18261,    25,\n",
      "          198,   464,  1074,  8793,  1049,  2482,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 63/220 [08:33<56:05, 21.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 31373,     6,   656,\n",
      "         4960,    13,   198, 21017, 18261,    25,   198,    39,  1872,     0,\n",
      "         4960,   318,   257,   845,  2408,  3303,   284,  2193,    13,   198,\n",
      "        21017, 18261,    25,   198, 10449,   345,   329,   534,  1037,     0],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|       | 64/220 [08:34<40:18, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "        23094,    13,   198,   198, 21017, 23412,    25,   198,  1544,   318,\n",
      "          845, 10787,    13,   679,  1464,  3640,   290,  3640,    13,   198,\n",
      "        21017, 18261,    25,   198,  1544,  3640,   290,  3640,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 65/220 [08:35<28:43, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705, 19276,  7609,  4458,   198,   198, 21017, 18261,    25,\n",
      "          198, 30946,  7609,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 66/220 [08:39<22:56,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,   326,  3544,\n",
      "          262,  1573,   564,   246,  1820, 11268,   447,   247,    13,   198,\n",
      "          198, 21017, 18261,    25,   198,  3666, 11268,   318,   257,  3381,\n",
      "          973,   284,  6901,  2130,   508,   318,   845,  8557,    11,   290,\n",
      "          318,   845,  7867,   416,   262, 19564,   286,   262, 39782,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|       | 67/220 [08:41<17:08,  6.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   257,  6171,  5177,   329,\n",
      "          705, 44152, 30960,   198, 21017, 18261,    25,   198,    32,  6171,\n",
      "         5177,   329,   705, 44152,     6,   318,   705, 17470,  4458],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 68/220 [08:42<12:50,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  3139,   286,  4881,\n",
      "           30,   198, 21017, 18261,    25,   198,   464,  3139,   286,  4881,\n",
      "          318,  6342,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|      | 69/220 [08:44<10:27,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705,   325, 25924,  4458,   198,   198, 21017, 18261,    25,\n",
      "          198,  4653, 25924,   318,   257,  1573,   326,  8477,   257,  1048,\n",
      "          508,   318,  9480,   290, 13160,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 70/220 [08:45<08:15,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  9546,   656,   257,\n",
      "         1844,  6827,    13,   198,   198, 21017, 23412,    25,   198,  3847,\n",
      "         6766,   198, 21017, 18261,    25,   198,   464,  1755,  6766,   318,\n",
      "         5901,   351,  5788,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|      | 71/220 [08:47<07:24,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,   262,  1115, 13737,   286,   262,\n",
      "         1578,  1829,  1230,    13,   198, 21017, 18261,    25,   198,   464,\n",
      "         1115, 13737,   286,   262,  1578,  1829,  1230,   389,   262,  4640,\n",
      "           11, 10828,    11,   290, 13657, 13737,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 72/220 [11:22<1:59:28, 48.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  9848,   422,  2511,\n",
      "         1547,   284,  7370,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "        46582,    14,    17,  2511,  1547,   198, 21017, 18261,    25,   198,\n",
      "        46582,    14,    17,  7370,   198, 21017, 18261,    25,   198, 46582,\n",
      "           14,    17,  7370,   198, 21017, 18261,    25,   198, 46582,    14,\n",
      "           17,  7370,   198, 21017, 18261,    25,   198, 46582,    14,    17,\n",
      "         7370,   198, 21017, 18261,    25,   198, 46582,    14,    17,  7370,\n",
      "          198, 21017, 18261,    25,   198, 46582,    14,    17,  7370,   198,\n",
      "        21017, 18261,    25,   198, 46582,    14,    17,  7370,   198, 21017,\n",
      "        18261,    25,   198, 46582,    14,    17,  7370,   198, 21017, 18261,\n",
      "           25,   198, 46582,    14,    17,  7370,   198, 21017, 18261,    25,\n",
      "          198, 46582,    14,    17,  7370,   198, 21017, 18261,    25,   198,\n",
      "        46582,    14,    17,  7370,   198, 21017, 18261,    25,   198, 46582,\n",
      "           14,    17,  7370,   198, 21017, 18261,    25,   198, 46582,    14,\n",
      "           17,  7370,   198, 21017, 18261,    25,   198, 46582,    14,    17,\n",
      "         7370,   198, 21017, 18261,    25,   198, 46582,    14,    17,  7370,\n",
      "          198, 21017, 18261,    25,   198, 46582,    14,    17,  7370,   198,\n",
      "        21017, 18261,    25,   198, 46582,    14,    17,  7370,   198, 21017,\n",
      "        18261,    25,   198, 46582,    14,    17,  7370,   198, 21017, 18261,\n",
      "           25,   198, 46582,    14,    17,  7370,   198, 21017, 18261,    25,\n",
      "          198, 46582,    14,    17,  7370,   198, 21017, 18261,    25,   198,\n",
      "        46582,    14,    17,  7370,   198, 21017, 18261,    25,   198, 46582,\n",
      "           14,    17,  7370,   198, 21017, 18261,    25,   198, 46582,    14,\n",
      "           17,  7370,   198, 21017, 18261,    25,   198, 46582,    14,    17,\n",
      "         7370,   198, 21017, 18261,    25,   198, 46582,    14,    17,  7370,\n",
      "          198, 21017, 18261,    25,   198, 46582,    14,    17,  7370,   198,\n",
      "        21017, 18261,    25,   198, 46582,    14,    17,  7370,   198, 21017,\n",
      "        18261,    25,   198, 46582,    14,    17,  7370,   198, 21017, 18261,\n",
      "           25], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|      | 73/220 [11:24<1:24:55, 34.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 16742,   262,  1306,   513,  2846,   287,\n",
      "          262,  1708,  8379,    25,   513,    11,   642,    11,   767,    11,\n",
      "          860,    13,   198, 21017, 18261,    25,   198,   464,  1306,  1115,\n",
      "         2846,   287,   262,  8379,   389,    25,   513,    11,   642,    11,\n",
      "          767,    11,   860,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 74/220 [11:25<59:33, 24.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15946,   485,   257,  6171,  5177,   329,\n",
      "          705, 37784,  4458,   198, 21017, 18261,    25,   198, 35700,    13],\n",
      "       device='cuda:0')\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "         2291,   257,  8718, 45693,    25,   705,    40,  1101,   845, 14720,\n",
      "         2637,   198,   198, 21017, 23412,    25,   198,    40,  1101,   845,\n",
      "        14720,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 76/220 [11:27<32:33, 13.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3351,   859,   903,   262,  1813,  9546,\n",
      "           13,   198,   198, 21017, 23412,    25,   198,    32, 27737,  1110,\n",
      "          287,   262,  3952,    13,   198, 21017, 18261,    25,   198,    32,\n",
      "        27737,  1110,   287,   262,  3952,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 77/220 [13:49<1:48:20, 45.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705, 13926,\n",
      "          873,  4458,   198, 21017, 18261,    25,   198, 28489,   873,   318,\n",
      "          262,  2050,   286,   262,  3773,   290,   262,  4542,   286,  3034,\n",
      "         9674,    13,   632,  3640,   262,  3773,   338,  3034,  4788,   290,\n",
      "          511,  2928,   319,   262,  3773,   338,  4290,   290,   262,  3773,\n",
      "          338,  3773,   355,   257,  2187,    13,   632,   635,  3640,   262,\n",
      "         3773,   338,  3034,  4568,   290,   511,  2928,   319,   262,  3773,\n",
      "          338,  4290,   290,   262,  3773,   338,  3773,   355,   257,  2187,\n",
      "           13,   198, 21017, 18261,    25,   198, 28489,   873,   318,   262,\n",
      "         2050,   286,   262,  3773,   290,   262,  4542,   286,  3034,  9674,\n",
      "           13,   632,  3640,   262,  3773,   338,  3034,  4788,   290,   511,\n",
      "         2928,   319,   262,  3773,   338,  4290,   290,   262,  3773,   338,\n",
      "         3773,   355,   257,  2187,    13,   632,   635,  3640,   262,  3773,\n",
      "          338,  3034,  4568,   290,   511,  2928,   319,   262,  3773,   338,\n",
      "         4290,   290,   262,  3773,   338,  3773,   355,   257,  2187,    13,\n",
      "          198, 21017, 18261,    25,   198, 28489,   873,   318,   262,  2050,\n",
      "          286,   262,  3773,   290,   262,  4542,   286,  3034,  9674,    13,\n",
      "          632,  3640,   262,  3773,   338,  3034,  4788,   290,   511,  2928,\n",
      "          319,   262,  3773,   338,  4290,   290,   262,  3773,   338,  3773,\n",
      "          355,   257,  2187,    13,   632,   635,  3640,   262,  3773,   338,\n",
      "         3034,  4568,   290,   511,  2928,   319,   262,  3773,   338,  4290,\n",
      "          290,   262,  3773,   338,  3773,   355,   257,  2187,    13,   198,\n",
      "        21017, 18261,    25,   198, 28489,   873,   318,   262,  2050,   286,\n",
      "          262,  3773,   290,   262,  4542,   286,  3034,  9674,    13,   632,\n",
      "         3640,   262,  3773,   338,  3034,  4788,   290,   511,  2928,   319,\n",
      "          262,  3773,   338,  4290,   290,   262,  3773,   338,  3773,   355,\n",
      "          257,  2187,    13,   632,   635,  3640,   262,  3773],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|      | 78/220 [13:51<1:20:40, 34.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   281,   281,  1122,  4948,\n",
      "          286,   705,   330,  7015,   378, 30960,   198, 21017, 18261,    25,\n",
      "          198,  2025,   281,  1122,  4948,   286,   705,   330,  7015,   378,\n",
      "            6,   318,   705,   301, 14991,  1096,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 79/220 [13:53<59:30, 25.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   428,  6827,   284,   923,\n",
      "          351,   366,  8332,  1298,  1375,  5257,   284,  5461,   607,   670,\n",
      "           11,  3584,   673,   373, 10032,    13,   198, 21017, 18261,    25,\n",
      "          198,  8332,   607, 10032,  1108,    11,   673,  5257,   284,  5461,\n",
      "          607,   670,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|      | 80/220 [13:54<43:36, 18.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705,  6214,   345,  2582,\n",
      "            6,   656,  4141,    13,   198, 21017, 18261,    25,   198, 22362,\n",
      "          443,   285, 14378,  1556,   443,   285, 14378,   766,   345,  2582,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 81/220 [13:56<31:55, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  5931, 10451,   329,\n",
      "         1660,    30,   198, 21017, 18261,    25,   198,   464,  5931, 10451,\n",
      "          329,  1660,   318,   367,    17,    46,    17,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 82/220 [13:57<23:15, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 41762,   262,  1708,  6827,   656,   257,\n",
      "         3141,    13,   198,   198, 21017, 23412,    25,   198,  1639,   815,\n",
      "         3424,   534,  2119,    13,   198, 21017, 18261,    25,   198,  1639,\n",
      "          815,  3424,   534,  2119,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 83/220 [14:00<18:19,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 16742,   257,  6171,  5177,   329,   262,\n",
      "         1813, 15942,    13,   198,   198, 21017, 23412,    25,   198,  5248,\n",
      "          461,   262,  6171,  5177,   329,   262,  1813, 15942,    13,   198,\n",
      "          198, 21017, 18261,    25,   198,    32,  6171,  5177,   329,   262,\n",
      "         1813, 15942,   318,   366,  1462,  2740,   526], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|      | 84/220 [14:02<14:05,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  1613, 20170,   286,\n",
      "          705, 11249, 30960,   198, 21017, 18261,    25,   198,   464,  1613,\n",
      "        20170,   286,   705, 11249,     6,   318,   705,  1462,  1382,  2637],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 85/220 [14:03<10:30,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705,  8496,   318,   262,\n",
      "        16936,  4436,  8348,   656,  8200,    13,   198, 21017, 18261,    25,\n",
      "          198,   464, 16936,  4436,   318,   287, 10598,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|      | 86/220 [14:04<07:57,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   939, 10700,   284, 18212,\n",
      "           13,   198, 21017, 18261,    25,   198,  2167, 10700,   318,   939,\n",
      "        18212,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 87/220 [14:06<06:43,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,    35,  2357,  3810,   262,  1181,   286,\n",
      "         2300,   329,  1660,   379,  1802,  7370, 34186,    13,   198, 21017,\n",
      "        18261,    25,   198,   464,  1181,   286,  2300,   329,  1660,   379,\n",
      "         1802,  7370, 34186,   318,  1660,   379,  2119,  5951,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 88/220 [14:07<05:32,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "        38695, 30960,   198, 21017, 18261,    25,   198,   464,  6697,   286,\n",
      "          705, 38695,     6,   318,   705, 11576,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|      | 89/220 [16:41<1:44:39, 47.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705,    65,\n",
      "         2101,  1608,  4458,   198, 21017, 18261,    25,   198,    33,  2101,\n",
      "         1608,   318,   257,  2099,   286,  2877, 26433,   326,  3407,  4695,\n",
      "           11,  6134,    11,   290, 33712,    13,   632,  3407,  4695,   326,\n",
      "          389, 22284,   452,  9610,    11,   884,   355, 10087,    11, 23426,\n",
      "           11,   290,  5916,    11,   290,  4695,   326,   389, 41919,  9610,\n",
      "           11,   884,   355, 41919,  2850,    11, 38255,  1547,    11,   290,\n",
      "        46617,    13,   347,  2101,  1608,  3407,  4695,   326,   389, 22284,\n",
      "          452,  9610,    11,   884,   355, 10087,    11, 23426,    11,   290,\n",
      "         5916,    11,   290,  4695,   326,   389, 41919,  9610,    11,   884,\n",
      "          355, 41919,  2850,    11, 38255,  1547,    11,   290, 46617,    13,\n",
      "          198,   198, 21017, 18261,    25,   198,    33,  2101,  1608,  3407,\n",
      "         4695,   326,   389, 22284,   452,  9610,    11,   884,   355, 10087,\n",
      "           11, 23426,    11,   290,  5916,    11,   290,  4695,   326,   389,\n",
      "        41919,  9610,    11,   884,   355, 41919,  2850,    11, 38255,  1547,\n",
      "           11,   290, 46617,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "           33,  2101,  1608,  3407,  4695,   326,   389, 22284,   452,  9610,\n",
      "           11,   884,   355, 10087,    11, 23426,    11,   290,  5916,    11,\n",
      "          290,  4695,   326,   389, 41919,  9610,    11,   884,   355, 41919,\n",
      "         2850,    11, 38255,  1547,    11,   290, 46617,    13,   198,   198,\n",
      "        21017, 18261,    25,   198,    33,  2101,  1608,  3407,  4695,   326,\n",
      "          389, 22284,   452,  9610,    11,   884,   355, 10087,    11, 23426,\n",
      "           11,   290,  5916,    11,   290,  4695,   326,   389, 41919,  9610,\n",
      "           11,   884,   355, 41919,  2850,    11, 38255,  1547,    11,   290,\n",
      "        46617,    13,   198,   198, 21017, 18261,    25,   198,    33,  2101,\n",
      "         1608,  3407,  4695,   326,   389, 22284,   452,  9610,    11,   884,\n",
      "          355, 10087,    11, 23426,    11,   290,  5916,    11,   290],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 90/220 [16:43<1:13:57, 34.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18438,   391,   644,   257,   387, 28643,\n",
      "          318,    13,   198, 21017, 18261,    25,   198,    32,   387, 28643,\n",
      "          318,   257, 21247, 13160,   286,   257,  2060,  1627,   286,  2420,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|     | 91/220 [16:45<52:30, 24.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,   262,  1429,   416,   543,  6134,\n",
      "          787,   511,  2057,    13,   198, 21017, 18261,    25,   198,   464,\n",
      "         1429,   416,   543,  6134,   787,   511,  2057,   318,  1444,  5205,\n",
      "        44411,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 92/220 [16:46<37:31, 17.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24203,   966,   286,\n",
      "         6953,    30,   198, 21017, 18261,    25,   198,   464, 24203,   966,\n",
      "          286,  6953,   318,  6702,   807,  2996,  7370, 35935,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|     | 93/220 [16:52<29:40, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705,  1990,\n",
      "          499,  6944,  4458,   198, 21017, 18261,    25,   198, 15200,   499,\n",
      "         6944,   318,   262,  1429,   416,   543,  1660, 20199,   287,   262,\n",
      "         1633,   318,  6928,   416,  1660, 20199,   287,   262,  1660,    13,\n",
      "          632,  8833,   618,  1660, 20199,   287,   262,  1633,   318,  6928,\n",
      "          416,  1660, 20199,   287,   262,  1660,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 94/220 [16:56<22:45, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3721,   286,   705,\n",
      "        46453,  4458,   198, 21017, 18261,    25,   198,    38, 16995,   318,\n",
      "          262,  2700,   326, 16194,  5563,   287,   257,  5969,  4571,    13,\n",
      "          632,   318,  6032,  8630,   287, 10700,   583,  1218,   393, 10700,\n",
      "          583,  1218,   583,  1218,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|     | 95/220 [16:59<18:09,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262, 16716,  3381,   705,\n",
      "          439,  2676,   341,  4458,   198, 21017, 18261,    25,   198,  3237,\n",
      "         2676,   341,   318,   257,  2099,   286, 40005,  2229,  9546,   287,\n",
      "          543,   257,  1573,   318,  5100,  1573,    12,  1640,    12,  4775,\n",
      "          351,   257,  1180,  1573,   422,   262,  2656,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 96/220 [17:01<13:36,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 22918,   286, 16871,\n",
      "        20584,  4610,    30,   198, 21017, 18261,    25,   198,   464, 22918,\n",
      "          286, 16871, 20584,  4610,   318,  6702,   513,    13,    15,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 97/220 [17:03<10:33,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   281,   281,  1122,  4948,\n",
      "          286,   705,  3372,   437, 30960,   198, 21017, 18261,    25,   198,\n",
      "         2025,   281,  1122,  4948,   286,   705,  3372,   437,     6,   318,\n",
      "          705, 20147,   437,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 98/220 [17:05<08:33,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8890,   489,  1958,   262,  5408,    25,\n",
      "          362,     7,    87,  1343,   513,     8,  1343,   604,     7,    87,\n",
      "          532,   352,   737,   198,   198, 21017, 18261,    25,   198,    17,\n",
      "            7,    87,  1343,   513,     8,  1343,   604,     7,    87,   532,\n",
      "          352,   737], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 99/220 [17:07<07:02,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9771,  3129,   378,   262, 38447,   286,\n",
      "          257,  9197,   351,   257, 14753,   286,   838, 12067,    13,   198,\n",
      "        20560,    25,   198, 20560,    25,   838, 12067,    13,   198, 21017,\n",
      "        18261,    25,   198, 20560,    25,   838, 12067,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|     | 100/220 [17:08<05:41,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  4738,  8379,   286,\n",
      "          838, 19561,    13,   198, 21017, 18261,    25,   198,   940, 19561,\n",
      "          318,   257,  4738,  8379,   286, 19561,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 101/220 [17:09<04:36,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 44402,   257, 11080, 43441,   284,  1844,\n",
      "          262,  6827,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         3807,   373,   220, 29343,    13,   198, 21017, 18261,    25,   198,\n",
      "          464,  3807,   373,   220, 29343,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|     | 102/220 [17:13<05:35,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "        23094,    13,   198,   198, 21017, 23412,    25,   198,   464,  6766,\n",
      "          318,   845,  4171,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464,  6766,   318,   257,  2769,  4171,    13,   198,   198, 21017,\n",
      "         7507,  2856,   287,   262, 23094,    25,   198,   464,  6766,   318,\n",
      "          257,  2769,  4171,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 103/220 [17:15<04:58,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24372,   966,   286,\n",
      "         1660,   379,  5417,  1241,    30,   198, 21017, 18261,    25,   198,\n",
      "          464, 24372,   966,   286,  1660,   379,  5417,  1241,   318,  6702,\n",
      "          532,  2548,  7370, 34186,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|     | 104/220 [17:16<04:13,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 23441,   286,   642,\n",
      "           30,   198, 21017, 18261,    25,   198,   464, 23441,   286,   642,\n",
      "          318,   642,    11, 23906,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 105/220 [17:21<05:31,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,  1544,\n",
      "          318,   845,  1913,    13,   679,   460, 10303,  1802,  8059,    13,\n",
      "          198, 21017, 18261,    25,   198,  1544,   318,   355,  1913,   355,\n",
      "          257,  6473,    13,   198, 21017, 18261,    25,   198,  1544,   318,\n",
      "          355,  1913,   355,   257,  6473,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 106/220 [17:22<04:27,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         2156,   318,   845,  1263,    13,   198, 21017, 18261,    25,   198,\n",
      "          464,  2156,   318,   845,  1263,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 107/220 [17:23<03:44,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  3139,   286,  2807,\n",
      "           30,   198, 21017, 18261,    25,   198,   464,  3139,   286,  2807,\n",
      "          318, 11618,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|     | 108/220 [17:25<03:47,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8053,   734,  6171, 43612,   329,   366,\n",
      "          600, 32940,   526,   198, 18261,    25,   198,    16,    13, 42486,\n",
      "          198,    17,    13, 49452,   198, 21017, 18261,    25,   198,    16,\n",
      "           13, 42486,   198,    17,    13, 49452], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 110/220 [19:50<57:30, 31.37s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18438,   391,   262,  2163,   286,   262,\n",
      "        14383,   287,   262,  1692,  1767,    13,   198, 21017, 18261,    25,\n",
      "          198,   464,  2163,   286,   262, 14383,   318,   284, 10385, 15701,\n",
      "          656,  2568,    13,   632,   318,  5140,   287,   262,  3641,   286,\n",
      "          262,  1767,   290,   318,  4497,   329, 23202, 15701,   656,  2568,\n",
      "           13,   632,   318,  5140,   287,   262, 14383,   290,   318,   262,\n",
      "         4387,  1618,   287,   262,  1692,  1767,    13,   632,   318, 13160,\n",
      "          286,  6702,   513,    11,   830,   284,   604,    11,   830,  4778,\n",
      "           13,   632,   318, 13160,   286,  6702,  1679,   284,  1542,  1411,\n",
      "          286,   262,  2472,  1767,  3463,    13,   632,   318, 13160,   286,\n",
      "         6702,  1679,   284,  1542,  1411,   286,   262,  2472,  1767,  3463,\n",
      "           13,   198,   198, 21017, 18261,    25,   198,   464,  2163,   286,\n",
      "          262, 14383,   318,   284, 10385, 15701,   656,  2568,    13,   632,\n",
      "          318,  5140,   287,   262,  3641,   286,   262,  1767,   290,   318,\n",
      "         4497,   329, 23202, 15701,   656,  2568,    13,   632,   318,  5140,\n",
      "          287,   262, 14383,   290,   318,   262,  4387,  1618,   287,   262,\n",
      "         1692,  1767,    13,   632,   318, 13160,   286,  6702,   513,    11,\n",
      "          830,   284,   604,    11,   830,  4778,    13,   632,   318, 13160,\n",
      "          286,  6702,  1679,   284,  1542,  1411,   286,   262,  2472,  1767,\n",
      "         3463,    13,   632,   318, 13160,   286,  6702,  1679,   284,  1542,\n",
      "         1411,   286,   262,  2472,  1767,  3463,    13,   198,   198, 21017,\n",
      "        18261,    25,   198,   464,  2163,   286,   262, 14383,   318,   284,\n",
      "        10385, 15701,   656,  2568,    13,   632,   318,  5140,   287,   262,\n",
      "         3641,   286,   262,  1767,   290,   318,  4497,   329, 23202, 15701,\n",
      "          656,  2568,    13,   632,   318,  5140,   287,   262, 14383,   290,\n",
      "          318,   262,  4387,  1618,   287,   262,  1692,  1767,    13,   632,\n",
      "          318, 13160,   286,  6702,   513,    11,   830,   284,   604,    11,\n",
      "          830,  4778], device='cuda:0')\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,   284,  2987,\n",
      "        16287,    25,   705,  1544,  2497,   326,   262,  6766,   373, 15114,\n",
      "         1336,  2637,   198,   198, 21017, 23412,    25,   198,  1544,  2497,\n",
      "          326,   262,  6766,   373, 15114,  1336,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|     | 111/220 [19:51<40:27, 22.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   477,\n",
      "         2676,   341,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         2344, 17948, 26625,    13,   198, 21017, 18261,    25,   198,   464,\n",
      "         2344, 17948, 26625,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 112/220 [19:53<29:05, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   281,   281,  1122,  4948,\n",
      "          329,   705, 24988,   589, 30960,   198, 21017, 18261,    25,   198,\n",
      "         2025,   281,  1122,  4948,   329,   705, 24988,   589,     6,   318,\n",
      "          705, 12501,   260,   589,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|    | 113/220 [19:57<22:40, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   428,  2420,   355,  2035,\n",
      "          257,  8364,   393,   257,  5337,    13,   198,   198, 21017, 23412,\n",
      "           25,   198, 20575,   500, 10601,    11,  7543,    11,   290,  9653,\n",
      "          287,   257,  9396,    13,   198, 21017, 18261,    25,   198,    32,\n",
      "         8364,   329,   257, 12187,  1444,   366,   464, 30799,   379,   262,\n",
      "         5268,   286,   262,   350, 33926,     1,   416, 12091,  2517,   268,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 114/220 [19:59<16:27,  9.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  1809,  6525,   428,  6827,   355,   257,\n",
      "         1808,    13,   198,   198, 21017, 23412,    25,   198,  7120,  3956,\n",
      "         1816,   284,  3576,   938,   614,    13,   198, 21017, 18261,    25,\n",
      "          198,  7120,  3956,  1816,   284,  3576,   938,   614,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|    | 115/220 [20:00<11:52,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705,   321, 14228,  4458,   198,   198, 21017, 18261,    25,\n",
      "          198,  5840, 14228,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 116/220 [22:34<1:28:36, 51.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,  1123,  6827,   355,  2035,\n",
      "         2377,   283,   876,    11, 15054,   876,    11, 23602,    11,   393,\n",
      "          409,   565,   321,  2870,    13,   198,   198, 21017, 23412,    25,\n",
      "          198,  6090,   345,  1037,   502,    30,   198, 21017, 18261,    25,\n",
      "          198,  3109,   565,   321,  2870,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198, 24361,   198,  3546,   525,   876,   198, 24361,   198,\n",
      "         3546,   525,   876,   198, 24361,   198,  3546,   525,   876,   198,\n",
      "        24361,   198,  3546,   525,   876,   198, 24361,   198,  3546,   525,\n",
      "          876,   198], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|    | 117/220 [22:35<1:02:00, 36.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  3146,   355,\n",
      "          772,   393,  5629,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "           17,    11,   642,    11,  1248,    11,  2310,    11,   513,   198,\n",
      "          198, 21017, 18261,    25,   198,  6104,   198,    46,  1860],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 118/220 [22:36<43:34, 25.64s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  5931, 10451,   329,\n",
      "         8268,    30,   198, 21017, 18261,    25,   198,   464,  5931, 10451,\n",
      "          329,  8268,   318, 11013,  2601,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 119/220 [22:41<32:26, 19.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 16742,   262,  5951,   286, 20884,  1660,\n",
      "          739,  3487, 20938,  3833,    13,   198, 20560,    25,   198,  9203,\n",
      "         3487, 20938,  3833,    11,   262,  5951,   286, 20884,  1660,   318,\n",
      "          532,  2548,  7370, 34186,    13,   198, 26410,    25,   198,  9203,\n",
      "         3487, 20938,  3833,    11,   262,  5951,   286, 20884,  1660,   318,\n",
      "          532,  2548,  7370, 34186,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 120/220 [22:42<23:16, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18378,   262,  1708,  6827,   284,   787,\n",
      "          340,   517,  8766,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "         1544,   338,  1392,   284,   766,   340,   284,  1975,   340,    13,\n",
      "          198, 21017, 18261,    25,   198,  1544,   338,  1392,   284,   766,\n",
      "          340,   284,  1975,   340,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 121/220 [22:44<16:39, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "        38171, 30960,   198, 21017, 18261,    25,   198,     6, 28406,     6,\n",
      "          318,   705, 26069,  2249,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|    | 122/220 [22:45<12:19,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 19400,   262,  1813, 15942,   284,   663,\n",
      "         1613, 12948,  1296,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "         4098,    11,  4144,    11,   711,    11,   711,   198, 21017, 18261,\n",
      "           25,   198,  4098,    11,  4144,    11,   711,    11,   711],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 123/220 [22:46<09:08,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 41762,   262,  1708,  6827,   656,   262,\n",
      "        14513,  3809,    13,   198,   198, 21017, 23412,    25,   198,  2990,\n",
      "          481,  1382,   257,   649,  3952,    13,   198,   198, 21017, 18261,\n",
      "           25,   198,  2990,   481,  1382,   257,   649,  3952,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|    | 124/220 [22:48<06:59,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,    36,  2100,  4985,   428,  6827,   329,\n",
      "        24993,   290, 23491, 10135,    13,   198,   198, 21017, 23412,    25,\n",
      "          198,    40,   307,   293,   425,   428,   318,   257, 48612,  2126,\n",
      "           13,   198, 21017, 18261,    25,   198,    40,  1975,   428,   318,\n",
      "          257, 48612,  2126,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 125/220 [22:49<05:26,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "         2971, 30960,   198, 21017, 18261,    25,   198,   464,  6697,   286,\n",
      "          705,  2971,     6,   318,   705, 23701,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|    | 126/220 [22:51<04:34,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 11274,  3329,     6,\n",
      "          656,  4141,    13,   198, 21017, 18261,    25,   198, 22362,   443,\n",
      "          285, 14378,  1556,   443,  5556,   386,  2395,  1556,   443,  5556,\n",
      "          386,  2395,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 127/220 [22:53<04:20,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   281,   281,  1122,  4948,\n",
      "          286,   705,  1676, 19741, 30960,   198, 21017, 18261,    25,   198,\n",
      "            6,  2964, 19741,     6,   318,   257,  3381,   973,   284,  6901,\n",
      "          257,  1048,   508,   318,  1464,  1762,  3371,   257,  3061,   393,\n",
      "         3061,  4634,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 128/220 [22:54<03:29,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "          779,   257, 23094,    25,   705,  9360,  8212,  7588,   510,   262,\n",
      "         2119,  2637,   198, 21017, 18261,    25,   198,  9360,  8212,  7588,\n",
      "          510,   262,  2119,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 129/220 [22:56<03:12,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  8234,  1864,\n",
      "          284,   663,  2099,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "        19184, 45690,   198,  3646,   388,   198, 30457,  2271,   198, 21017,\n",
      "        18261,    25,   198, 19184, 45690,   198,  3646,   388,   198, 30457,\n",
      "         2271], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|    | 130/220 [22:58<03:12,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6616,  6808,   286,\n",
      "         5598,    30,   198, 21017, 18261,    25,   198,   464,  6616,  6808,\n",
      "          286,  5598,   318,   513,    13,   198, 21017, 18261,    25,   198,\n",
      "          464,  6616,  6808,   286,  5598,   318,   513,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 131/220 [22:59<02:37,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   281,\n",
      "         4686, 29005,    13,   198,   198, 21017, 23412,    25,   198,  1544,\n",
      "          318,   845,  5527,    13,   198, 21017, 18261,    25,   198,  1544,\n",
      "          318,   845,  5527,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 132/220 [25:29<1:07:41, 46.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  5044,   355,\n",
      "        41919,   382,    11, 21047,   452,   382,    11,   393, 22284,   452,\n",
      "          382,    13,   198,   198, 21017, 23412,    25,   198,  5005,   263,\n",
      "          198, 42562,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49, 14229,   198,    49, 14229,\n",
      "          198,    49, 14229,   198,    49, 14229,   198,    49, 14229,   198,\n",
      "           49, 14229,   198,    49, 14229,   198,    49, 14229,   198,    49,\n",
      "        14229,   198,    49, 14229,   198,    49], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|    | 133/220 [25:32<48:09, 33.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705,   325, 10920,   541,   414,  4458,   198,   198, 21017,\n",
      "        18261,    25,   198,  4653, 10920,   541,   414,   318,   257,  4950,\n",
      "         1517,    13,   632,   318,   262,  2694,   284,   766,   262,  2003,\n",
      "          290,   407,   307,  5421,   416,   340,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 134/220 [25:34<34:16, 23.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705, 31092,   913,  4458,   198, 21017, 18261,    25,   198,\n",
      "        26198,   913,   318,   257,  1573,   326,  8477,  2130,   508,   318,\n",
      "         1464,  2045,   329,   649,  2842,   284,   779,   511,  4133,    13],\n",
      "       device='cuda:0')\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  2378,    25,\n",
      "        15554,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 136/220 [25:36<18:38, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,   640,   705, 33698,\n",
      "         2250,     6,   656,  3210,  1105,    12,  9769,  8801,  5794,    13,\n",
      "          198, 21017, 18261,    25,   198,   464,   640,   705, 33698,  2250,\n",
      "            6,   318,   257,  3210,  1105,    12,  9769,  8801,  5794,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|   | 137/220 [25:37<14:10, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "         6171,  5177,    13,   198,   198, 21017, 23412,    25,   198,  1026,\n",
      "          338,  4692,  2354,    13,   198, 21017, 18261,    25,   198,  1026,\n",
      "          338,  4692,  2354,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 138/220 [25:38<10:49,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   718,  6578,   364,   284,\n",
      "         3939,  6392,   364,    13,   198, 21017, 18261,    25,   198,    21,\n",
      "         6578,   364,   318,   718,  3939,  6392,   364,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|   | 139/220 [25:39<08:13,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  3139,   286,  7137,\n",
      "           30,   198, 21017, 18261,    25,   198,   464,  3139,   286,  7137,\n",
      "          318, 28760,    13], device='cuda:0')\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 19400,   262,  1708,  6827,   284,  1613,\n",
      "        12948, 20170,    13,   198,   198, 21017, 23412,    25,   198,  2990,\n",
      "         5461,   262,   983,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 141/220 [25:43<05:31,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 13065,  3876,  1096,   262,  7505,   286,\n",
      "          705,   464,  3878,   402,  1381,  1525,  4458,   198, 21017, 18261,\n",
      "           25,   198,   464,  7505,   286,   705,   464,  3878,   402,  1381,\n",
      "         1525,     6,   318,   262,  3160,   286,   262,  3435,    11,   511,\n",
      "         6958,    11,   290,   511,  4888,  6461,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 142/220 [25:44<04:35,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 38727,   262, 30806,  2456,   287,   262,\n",
      "         1708,  6827,    13,   198,   198, 21017, 23412,    25,   198,  1135,\n",
      "         1816,   284,   766,   284,   262, 12269,    13,   198, 21017, 18261,\n",
      "           25,   198,  1135,  1816,   284,   766,   284,   262, 12269,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 143/220 [25:45<03:44,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   642, 37075,   284, 16379,\n",
      "           13,   198, 21017, 18261,    25,   198,    20, 37075,   318,   642,\n",
      "        16379,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|   | 144/220 [25:47<03:09,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  4738,   807,    12,\n",
      "        27003,  1271,    13,   198, 21017, 18261,    25,   198,    23,    13,\n",
      "          198, 21017, 18261,    25,   198,    23,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 145/220 [25:49<02:50,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "        39624, 30960,   198, 21017, 18261,    25,   198,   464,  6697,   286,\n",
      "          705, 39624,     6,   318,   705,   301,  7928,   278,  4458],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|   | 146/220 [25:50<02:31,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   262,  3381,   705,    82,\n",
      "        24196,  2478,     6,   656,  2679,    13,   198, 21017, 18261,    25,\n",
      "          198,    50,   494,   479,   455,   316,  1658,   479,   455,   316,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 147/220 [25:51<02:08,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  1708,  2643,   656,\n",
      "          281,   409, 20931,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "         1212,   318,  4998,     0,   198,  3109, 20931,    25,   198,  1212,\n",
      "          318,  4998,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|   | 148/220 [25:53<02:05,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  2378,   355,  2035,\n",
      "          257, 13020,   393,   257,  8234,    13,   198,   198, 21017, 23412,\n",
      "           25,   198, 10842,   265,   198,    37,  4872,   198,    38,  3201,\n",
      "          198, 21017, 18261,    25,   198,    37,  4872,   198,    38,  3201],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 149/220 [25:55<02:07,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 24372,   966,   286,\n",
      "         1660,   739,  3210,  3403,    30,   198, 21017, 18261,    25,   198,\n",
      "         9203,  3487,  3403,    11,   262, 24372,   966,   286,  1660,   318,\n",
      "         6702, 23679,  7370, 35935,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 150/220 [25:57<02:10,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262, 20170,   973,   287,\n",
      "          262,  6827,    13,   198,   198, 21017, 23412,    25,   198,  2990,\n",
      "          550,  7342,   262,  3807,    13,   198, 21017, 18261,    25,   198,\n",
      "          464, 20170,   973,   287,   262,  6827,   318,   366,  2990,  7342,\n",
      "          262,  3807,   526], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 151/220 [26:00<02:31,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "         2291,   257,  1048,  2649,    13,   198,   198, 21017, 23412,    25,\n",
      "          198,   464,  2344,   318,   845,  1913,  1909,    13,   198,   198,\n",
      "        21017, 18261,    25,   198,   464,  2344,   318,   845,  1913,  1909,\n",
      "           13,   198,   198, 21017, 17738,    25,   198, 15439,  2649,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|   | 152/220 [26:01<02:19,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 26254,   262,  1708,  6827,   656,   734,\n",
      "           11,  5291,   262,  2656,  3616, 16572,    13,   198,   198, 21017,\n",
      "        23412,    25,   198,  3347, 22979,   257, 12187,   290,   788,   673,\n",
      "        24789,   340,    13,   198, 21017, 18261,    25,   198,  3347, 22979,\n",
      "          257, 12187,   290, 24789,   340,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 153/220 [26:05<02:48,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15056,   257,  1351,   286,  2237,  9391,\n",
      "           11,  2922,   262,   734,   749,  6393,   329,  1642,   257, 12187,\n",
      "           13,   198,   198, 21017, 23412,    25,   198,    82, 35652,    11,\n",
      "        10601,    11,  9653,    11,  8268,    11, 16858,    11,  1660,    13,\n",
      "          198, 21017, 18261,    25,   198,    82, 35652,    11, 10601,    11,\n",
      "         9653,    11,  8268,    11, 16858,    11,  1660,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 154/220 [26:06<02:14,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 36246,   329,   705,\n",
      "         9930,   481, 30960,   198, 21017, 18261,    25,   198,  2990,   481,\n",
      "          307,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|   | 155/220 [26:07<01:57,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 22988,     6,   656,\n",
      "         4141,    13,   198, 21017, 18261,    25,   198, 14772,   410,   494,\n",
      "          390,  8591,   410,   494,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|   | 156/220 [26:09<02:01,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  2378,   355,  2035,\n",
      "          257,  8234,   393,   257, 20236,    13,   198,   198, 21017, 23412,\n",
      "           25,   198, 13787,  5549,   198, 26979,  1136,   540,   198, 20560,\n",
      "           25,   198, 26979,  1136,   540,   198, 21017, 18261,    25,   198,\n",
      "        26979,  1136,   540], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 157/220 [26:10<01:45,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "          779,   257, 23094,    25,   705,  9360, 20263,   318,   588,  2647,\n",
      "         2637,   198, 21017, 18261,    25,   198,  9360, 20263,   318,   588,\n",
      "         2647,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 158/220 [28:56<52:36, 50.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 39315,  1096,  1123,  1573,   287,   262,\n",
      "         6827,    13,   198,   198, 21017, 23412,    25,   198,  1169,  1492,\n",
      "          318,   319,   262,  3084,   198,  1169,  1492,   318,   319,   262,\n",
      "         3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,\n",
      "         1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,   319,\n",
      "          262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,\n",
      "         1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,\n",
      "          319,   262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,\n",
      "          198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,\n",
      "          318,   319,   262,  3084,   198,  1169,  1492,   318,   319,   262,\n",
      "         3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,\n",
      "         1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,   319,\n",
      "          262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,\n",
      "         1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,\n",
      "          319,   262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,\n",
      "          198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,\n",
      "          318,   319,   262,  3084,   198,  1169,  1492,   318,   319,   262,\n",
      "         3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,\n",
      "         1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,   319,\n",
      "          262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,\n",
      "         1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,\n",
      "          319,   262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,\n",
      "          198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,\n",
      "          318,   319,   262,  3084,   198,  1169,  1492,   318,   319,   262,\n",
      "         3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,  1169,\n",
      "         1492,   318,   319,   262,  3084,   198,  1169,  1492,   318,   319,\n",
      "          262,  3084,   198,  1169,  1492,   318,   319,   262,  3084,   198,\n",
      "         1169,  1492,   318,   319,   262,  3084,   198,  1169,  1492,   318],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|  | 159/220 [28:58<36:45, 36.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "          779,   257,   985,   576,    25,   383,  1097, 32897,   866,   262,\n",
      "         2975,    13,   198, 21017, 18261,    25,   198,   464,  1097, 32897,\n",
      "          866,   262,  2975,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 160/220 [29:00<25:59, 26.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 20575,   500,   262,   734,  4213,   287,\n",
      "          262,  6827,    13,   198,   198, 21017, 23412,    25,   198, 28768,\n",
      "          318,   922,   329,  1535,    13,   632,   460,   307,   256,  3428,\n",
      "           13,   198, 21017, 18261,    25,   198, 28768,   318,   922,   329,\n",
      "         1535,    13,   632,   460,   307,   256,  3428,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|  | 161/220 [29:02<18:18, 18.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262,  1388,  2426,   287,\n",
      "          262,  6827,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         6568,  2444,  4966,   284,   262, 24817,    13,   198, 21017, 18261,\n",
      "           25,   198,   464,  6568,  2444,  4966,   284,   262, 24817,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 162/220 [29:04<13:08, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,   257,  6171,  5177,   329,   705,\n",
      "          648,   563,  2637,   198,   198, 21017, 18261,    25,   198,    32,\n",
      "         6171,  5177,   329,   705,   648,   563,     6,   318,   705,   301,\n",
      "         2790,  2637], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|  | 163/220 [29:05<09:31, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 20575,   500,   262,   734, 13439,   656,\n",
      "          257,  2060, 24870,  6827,    13,   198,   198, 21017, 23412,    25,\n",
      "          198,  3347,  9713,  1327,    13,  1375,  3804,   262,  2814,    13,\n",
      "          198, 21017, 18261,    25,   198,  3347,  9713,  1327,    13,  1375,\n",
      "         3804,   262,  2814,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 164/220 [29:14<09:04,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18438,   391,   262,  1429,   286, 33607,\n",
      "           13,   198, 21017, 18261,    25,   198,   464,  1429,   286, 33607,\n",
      "          318,   262,  1429,   416,   543, 21678,   389, 11513,   656,  8122,\n",
      "          393,  4735,   416,  4894,    13,   632,  6032,  8833,   618, 21678,\n",
      "          389, 16968,   284,   257,  5951,  2440,   621,  3487,    11,  7186,\n",
      "          287,   262,  2650,   286, 21678,   326,   389,   407,  6032,  1944,\n",
      "          287,  3450,    13,   770,  1429,  6032,  2482,   287,   262,  2650,\n",
      "          286,  6588, 17556,    11, 11863,    11,   290,  1660, 20199,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 165/220 [29:16<06:37,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  1813,  6827,   656,\n",
      "         4075,  3809,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         6961,   373,  6325,   416,   262,  5583,    13,   198, 21017, 18261,\n",
      "           25,   198,   464,  6961,   373,  6325,   416,   262,  5583,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 166/220 [29:17<04:51,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
      "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
      "         1097,   318,   845,  3049,    13,   198, 21017, 18261,    25,   198,\n",
      "          464,  1097,   318,   845,  3049,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 167/220 [29:21<04:29,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,  2099,   286,  6279,   318,  6032,\n",
      "         3917,   351, 18355, 38563,    30,   198, 21017, 18261,    25,   198,\n",
      "           32, 18355, 12135,   318,   257,  2099,   286,  6388,   326,  6032,\n",
      "         8833,   287,   262,  6672,   393,  6180,    13,   632,  6032, 11073,\n",
      "         8157, 18355, 38563,   290,   460,  4439,  1913, 13520,   290,  6290,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|  | 168/220 [29:23<03:36,  4.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  5376,   262,  1772,   286,   705,  6836,\n",
      "          485,   290,  3771, 10456,   501,  4458,   198, 21017, 18261,    25,\n",
      "          198,   464,  1772,   286,   705,  6836,   485,   290,  3771, 10456,\n",
      "          501,     6,   318,  4502, 16197, 18193,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 169/220 [29:25<02:50,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 27458,  6194,   329,\n",
      "        43107,    30,   198, 21017, 18261,    25,   198,   464, 27458,  6194,\n",
      "          329, 43107,   318,  5870,  2601,    17,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|  | 170/220 [29:26<02:13,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 42779,   262, 21025,  2288,   287,   262,\n",
      "         6827,    13,   198,   198, 21017, 23412,    25,   198, 20459,   640,\n",
      "          284,   467,  1363,    13,   198, 21017, 18261,    25,   198, 20459,\n",
      "          640,   284,   467,  1363,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 171/220 [29:27<01:54,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,    13,   198,\n",
      "          198, 21017, 23412,    25,   198,   464, 19143,   373,  6793,   287,\n",
      "          257,  1598,  5642,    13,   198,   198, 21017, 18261,    25,   198,\n",
      "          464, 19143,   373,  6793,   287,   257,  1598,  5642,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 172/220 [31:42<33:43, 42.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257, 36102, 49533,    13,\n",
      "          198, 21017, 18261,    25,   198,  2025, 49533,   318,   257,  1621,\n",
      "         1297,   416,   281,  1981,   393,   257,  1448,   286,  3925,   326,\n",
      "          318,  1912,   319,   257,  2081,  1785,    13,  1052, 49533,  6032,\n",
      "         3033,   257,  1048,   393,   257,  1448,   286,   661, 24986,   351,\n",
      "          257, 36102,  2071,   393,  2071,   326,   484,   389,  6476,    13,\n",
      "         1052, 49533,  6032,  3033,   257, 36102,  2071,   393,  2071,   326,\n",
      "          484,   389,  6476,    13,   198, 21017, 18261,    25,   198,  2025,\n",
      "        49533,   318,   257,  1621,  1297,   416,   281,  1981,   393,   257,\n",
      "         1448,   286,  3925,   326,   318,  1912,   319,   257,  2081,  1785,\n",
      "           13,  1052, 49533,  6032,  3033,   257,  1048,   393,   257,  1448,\n",
      "          286,   661, 24986,   351,   257, 36102,  2071,   393,  2071,   326,\n",
      "          484,   389,  6476,    13,  1052, 49533,  6032,  3033,   257, 36102,\n",
      "         2071,   393,  2071,   326,   484,   389,  6476,    13,   198, 21017,\n",
      "        18261,    25,   198,  2025, 49533,   318,   257,  1621,  1297,   416,\n",
      "          281,  1981,   393,   257,  1448,   286,  3925,   326,   318,  1912,\n",
      "          319,   257,  2081,  1785,    13,  1052, 49533,  6032,  3033,   257,\n",
      "         1048,   393,   257,  1448,   286,   661, 24986,   351,   257, 36102,\n",
      "         2071,   393,  2071,   326,   484,   389,  6476,    13,  1052, 49533,\n",
      "         6032,  3033,   257, 36102,  2071,   393,  2071,   326,   484,   389,\n",
      "         6476,    13,   198, 21017, 18261,    25,   198,  2025, 49533,   318,\n",
      "          257,  1621,  1297,   416,   281,  1981,   393,   257,  1448,   286,\n",
      "         3925,   326,   318,  1912,   319,   257,  2081,  1785,    13,  1052,\n",
      "        49533,  6032,  3033,   257,  1048,   393,   257,  1448,   286,   661,\n",
      "        24986,   351,   257, 36102,  2071,   393,  2071,   326,   484,   389,\n",
      "         6476,    13,  1052, 49533,  6032,  3033,   257, 36102,  2071,   393,\n",
      "         2071,   326,   484,   389,  6476,    13], device='cuda:0')\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262,  3376, 24993,    25,\n",
      "          705,  8344, 12311,     6,   393,   705,   260, 15164,  4458],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|  | 174/220 [31:49<18:36, 24.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 16447,   257,  6827,  1262,   262,  1573,\n",
      "          705,    77,   455, 47111,  4458,   198, 21017, 18261,    25,   198,\n",
      "           45,   455, 47111,   318,   257,  1913,  9942,   326,   460,   307,\n",
      "         2936,   287,   262,  1613,    13,   632,   460,   307,  1775,   355,\n",
      "          257,  2565,   286, 30889,    11,   257,  2565,   286, 30889,   460,\n",
      "          307,  2936,   287,   262,  1613,    11,   290,   340,   460,   307,\n",
      "         1775,   355,   257,  1913,  9942,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 175/220 [34:22<42:02, 56.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  3146,   355,\n",
      "         6994,   393, 24185,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "           25,  1367,    11,  1478,    11,   678,    13,   198,    25,  1315,\n",
      "           11,  1160,    13,   198,    25,  1467,    11,  2310,    13,   198,\n",
      "           25,  1596,    11,  2534,    13,   198,    25,  1248,    11,  2242,\n",
      "           13,   198,    25,   678,    11,  1987,    13,   198,    25,  1160,\n",
      "           11,  1679,    13,   198,    25,  2310,    11,  2608,    13,   198,\n",
      "           25,  2534,    11,  2681,    13,   198,    25,  2242,    11,  2579,\n",
      "           13,   198,    25,  1987,    11,  2808,    13,   198,    25,  1679,\n",
      "           11,  1542,    13,   198,    25,  2608,    11,  3261,    13,   198,\n",
      "           25,  2681,    11,  3933,    13,   198,    25,  2579,    11,  4747,\n",
      "           13,   198,    25,  2808,    11,  4974,    13,   198,    25,  1542,\n",
      "           11,  3439,    13,   198,    25,  3261,    11,  4570,    13,   198,\n",
      "           25,  3933,    11,  5214,    13,   198,    25,  4747,    11,  4353,\n",
      "           13,   198,    25,  4974,    11,  5014,    13,   198,    25,  3439,\n",
      "           11,  2319,    13,   198,    25,  4570,    11,  6073,    13,   198,\n",
      "           25,  5214,    11,  5433,    13,   198,    25,  4353,    11,  5946,\n",
      "           13,   198,    25,  5014,    11,  5846,    13,   198,    25,  2319,\n",
      "           11,  4153,    13,   198,    25,  6073,    11,  6337,    13,   198,\n",
      "           25,  5433,    11,  6298,    13,   198,    25,  5946,    11,  4764,\n",
      "           13,   198,    25,  5846,    11,  5125,    13,   198,    25,  4153,\n",
      "           11,  2026,    13,   198,    25,  6337,    11,  6885,    13,   198,\n",
      "           25,  6298,    11,  6740,    13,   198,    25,  4764,    11,  7192,\n",
      "           13,   198,    25,  5125,    11,  7175,    13,   198,    25,  2026,\n",
      "           11,  5996,    13,   198,    25,  6885,    11,  7265,    13,   198,\n",
      "           25,  6740,    11,  7632,    13,   198,    25,  7192,    11,  7618,\n",
      "           13,   198,    25,  7175,    11,  7863,    13,   198,    25,  5996,\n",
      "           11,  3126,    13,   198,    25,  7265,    11,  8454,    13,   198,\n",
      "           25,  7632,    11], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 176/220 [34:23<30:33, 41.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  3139,   286, 16490,\n",
      "           30,   198, 21017, 18261,    25,   198,   464,  3139,   286, 16490,\n",
      "          318, 31104,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 177/220 [34:24<22:00, 30.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "           86,   316, 30960,   198, 21017, 18261,    25,   198,   464,  6697,\n",
      "          286,   705,    86,   316,     6,   318,   705, 39140,  4458],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|  | 178/220 [34:25<15:41, 22.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 33234,  1958,   262,  2099,   286,  6827,\n",
      "           13,   198,   198, 21017, 23412,    25,   198, 11633,   345,  5461,\n",
      "          262,   989,    30,   198, 21017, 18261,    25,   198,   464,  2099,\n",
      "          286,  6827,   318, 23602,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 179/220 [34:26<11:11, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  5931,  6194,   329,\n",
      "        27394,    30,   198, 21017, 18261,    25,   198,   464,  5931,  6194,\n",
      "          329, 27394,   318,   367,    70,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 180/220 [34:31<08:36, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 24564,  4892,   262,  1429,   286,  4075,\n",
      "         4839,   287,  4778,    13,   198, 21017, 18261,    25,   198, 13739,\n",
      "         4839,   318,   262,  3356,   286,  4778,   832,   257,  1813,  1989,\n",
      "          286,  2272,    13,   632,  6032,  8833,   618,  4778,   389,  3888,\n",
      "          422,   530,  1295,   284,  1194,   416,  4695,    11,   393,   416,\n",
      "         5384,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%| | 181/220 [34:32<06:10,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  3709,   355,\n",
      "         2035,  4735,    11,  8122,    11,   393,  3623,    13,   198,   198,\n",
      "        21017, 23412,    25,   198, 42981,  1601,    11, 11863,    11,  4898,\n",
      "          198, 21017, 18261,    25,   198, 46933,   198,    46,  5431,  5235,\n",
      "          198, 22911], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 182/220 [34:33<04:25,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   513, 18212,   284, 10700,\n",
      "           13,   198, 21017, 18261,    25,   198,    18, 18212,   318, 20343,\n",
      "        10700,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%| | 183/220 [34:34<03:13,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   262,  6827,   284,   779,\n",
      "          281, 35639, 28636,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "        28211,  1364,   257,  3465,    13,   198, 21017, 18261,    25,   198,\n",
      "           32,  3465,   373,  1364,   416,  2130,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 184/220 [34:35<02:19,  3.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15946,   485,   257,  6171,  5177,   329,\n",
      "          705, 41194,   863,  4458,   198, 21017, 18261,    25,   198, 40127,\n",
      "          863], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%| | 185/220 [34:36<01:47,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,   326,  5679,\n",
      "          262,  3912,    25,   366, 12295,   423,   314,  1683,   220, 29343,\n",
      "         1231,   220, 29343,     1,   198, 21017, 18261,    25,   198, 12295,\n",
      "          423,   314,  1683,  1231,  1231,  1231,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 186/220 [34:40<01:56,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 31686,   503,   262, 43441,   422,   262,\n",
      "         1708,  1351,    13,   198,   198, 21017, 23412,    25,   198,  5143,\n",
      "           11,  7331,    11,  2952,   198,   198, 21017, 18261,    25,   198,\n",
      "         5143,    11,  7331,    11,  2952,   198,   198, 21017,  1345,  1523,\n",
      "           25,   198,  5143,    11,  7331,    11,  2952,   198, 21017, 18261,\n",
      "           25,   198,  5143,    11,  7331,    11,  2952], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 187/220 [34:41<01:29,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,  8576, 16379,   284, 37075,\n",
      "           13,   198, 21017, 18261,    25,   198, 12825, 16379,   318,  8576,\n",
      "        37075,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 188/220 [34:42<01:08,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "        22089, 30960,   198, 21017, 18261,    25,   198, 29744,   318, 19337,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 189/220 [34:44<01:01,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,    34, 47467,  1096,   262,  1813,  1351,\n",
      "          286,  4695,    13,   198,   198, 21017, 23412,    25,   198,  2484,\n",
      "          668,    11, 44576,    11, 42542,    11, 37007,   198, 21017, 18261,\n",
      "           25,   198,    46, 40989,    11, 28616,    11, 44576,    11, 42542,\n",
      "           11, 37007], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%| | 190/220 [36:52<19:56, 39.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 32016,     6,   656,\n",
      "         7897,    13,   198, 21017, 18261,    25,   198, 22362, 21162,   300,\n",
      "         2768,  4533,   257,  8591,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951,\n",
      "         9195,  4951,  9195,  4951,  9195,  4951,  9195,  4951],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 191/220 [36:54<13:47, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705, 49229,\n",
      "        45693,  4458,   198, 20560,    25,   198, 38197, 45693,   318,   257,\n",
      "         3381,   973,   284,  6901,   257,  2643,   326,   318, 25291,   287,\n",
      "         1502,   284,   787,   340,   517,  7187,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%| | 192/220 [36:56<09:36, 20.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 15496,     6,   656,\n",
      "         3394,    13,   198, 21017, 18261,    25,   198,   140,   254, 35072,\n",
      "        21727, 21727, 31583, 18849,   140,   117, 12466,   254, 35072, 21727,\n",
      "        21727, 31583, 18849,   140,   117,     0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 193/220 [37:04<07:30, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705,  5116,\n",
      "         5139,  2568,  4458,   198, 20560,    25,   198, 49681,  5139,  2568,\n",
      "          318,   262,  2033,   286,  2700,   326,   460,   307,  5625,   284,\n",
      "          281,  2134,   416,   257,  1048,  1262,   262,   976,  2033,   286,\n",
      "         2700,   355,   484,   561,   779,   284,  3714,   257,  2613,    13,\n",
      "          198, 26410,    25,   198, 49681,  5139,  2568,   318,  6702,   352,\n",
      "           13,    15,   474,   280,   829,    13,   198, 21017, 18261,    25,\n",
      "          198, 49681,  5139,  2568,   318,  6702,   352,    13,    15,   474,\n",
      "          280,   829,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 194/220 [37:05<05:13, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "         8940, 30960,   198, 21017, 18261,    25,   198,   464,  6697,   286,\n",
      "          705,  8940,     6,   318,   705, 36673,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 195/220 [37:06<03:40,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   642,  4608,   284, 18212,\n",
      "           13,   198, 21017, 18261,    25,   198,    20,  4608,   318,  6702,\n",
      "          513,    13,  2998, 18212,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%| | 196/220 [37:08<02:38,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  5931, 10451,   329,\n",
      "        33525, 22443,   378,    30,   198, 21017, 18261,    25,   198,   464,\n",
      "         5931, 10451,   329, 33525, 22443,   378,   318,   337,    70, 15821,\n",
      "           19,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 197/220 [37:10<02:02,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 30003,  6525,   262,  1708,  6827,   284,\n",
      "         6330,   597, 43973, 20144,    13,   198,   198, 21017, 23412,    25,\n",
      "          198,  1026,   338,   257,  3704,   286, 12187,    13,   198, 21017,\n",
      "        18261,    25,   198,    32,  3704,   286, 12187,    30,   198, 21017,\n",
      "        18261,    25,   198,    32,  3704,   286, 12187,    30],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 198/220 [39:22<15:53, 43.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8053,  1936,  1180,  3858,   286, 13701,\n",
      "           13,   198, 20560,    25,   198,    16,    13,  2806, 34544,   198,\n",
      "           17,    13,  2806, 34544,    11,  2806, 34544,    11,  2806, 34544,\n",
      "          198,    18,    13,  2806, 34544,    11,  2806, 34544,    11,  2806,\n",
      "        34544,   198,    19,    13,  2806, 34544,    11,  2806, 34544,    11,\n",
      "         2806, 34544,   198,    20,    13,  2806, 34544,    11,  2806, 34544,\n",
      "           11,  2806, 34544,   198,    21,    13,  2806, 34544,    11,  2806,\n",
      "        34544,    11,  2806, 34544,   198,    22,    13,  2806, 34544,    11,\n",
      "         2806, 34544,    11,  2806, 34544,   198,    23,    13,  2806, 34544,\n",
      "           11,  2806, 34544,    11,  2806, 34544,   198,    24,    13,  2806,\n",
      "        34544,    11,  2806, 34544,    11,  2806, 34544,   198,   940,    13,\n",
      "         2806, 34544,    11,  2806, 34544,    11,  2806, 34544,   198,  1157,\n",
      "           13,  2806, 34544,    11,  2806, 34544,    11,  2806, 34544,   198,\n",
      "         1065,    13,  2806, 34544,    11,  2806, 34544,    11,  2806, 34544,\n",
      "          198,  1485,    13,  2806, 34544,    11,  2806, 34544,    11,  2806,\n",
      "        34544,   198,  1415,    13,  2806, 34544,    11,  2806, 34544,    11,\n",
      "         2806, 34544,   198,  1314,    13,  2806, 34544,    11,  2806, 34544,\n",
      "           11,  2806, 34544,   198,  1433,    13,  2806, 34544,    11,  2806,\n",
      "        34544,    11,  2806, 34544,   198,  1558,    13,  2806, 34544,    11,\n",
      "         2806, 34544,    11,  2806, 34544,   198,  1507,    13,  2806, 34544,\n",
      "           11,  2806, 34544,    11,  2806, 34544,   198,  1129,    13,  2806,\n",
      "        34544,    11,  2806, 34544,    11,  2806, 34544,   198,  1238,    13,\n",
      "         2806, 34544,    11,  2806, 34544,    11,  2806, 34544,   198,  2481,\n",
      "           13,  2806, 34544,    11,  2806, 34544,    11,  2806, 34544,   198,\n",
      "         1828,    13,  2806, 34544,    11,  2806, 34544,    11,  2806, 34544,\n",
      "          198,  1954,    13,  2806, 34544,    11,  2806, 34544,    11,  2806,\n",
      "        34544,   198,  1731,    13,  2806, 34544,    11], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%| | 199/220 [39:23<10:43, 30.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   767, 18212,   284, 10700,\n",
      "           13,   198, 21017, 18261,    25,   198,    22, 18212,   318, 50205,\n",
      "        10700,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%| | 200/220 [39:24<07:16, 21.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "        23701, 30960,   198, 21017, 18261,    25,   198,   464,  6697,   286,\n",
      "          705, 23701,     6,   318,   705,  2971,  4458], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|| 201/220 [39:26<04:58, 15.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  1613, 20170,   286,\n",
      "          705, 12215, 30960,   198, 21017, 18261,    25,   198,   464,  1613,\n",
      "        20170,   286,   705, 12215,     6,   318,   705, 12215,  2637],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 202/220 [39:27<03:25, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262, 18955, 10451,   329,\n",
      "         6588, 17556,    30,   198, 21017, 18261,    25,   198,   464, 18955,\n",
      "        10451,   329,  6588, 17556,   318,  7375,    17,    13],\n",
      "       device='cuda:0')\n",
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3103,  1851,   428,  6827,   284, 14513,\n",
      "         3809,   198,   198, 21017, 23412,    25,   198,   464, 16985,   877,\n",
      "        48024,   262,  6134,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 204/220 [39:29<01:44,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  1613, 20170,   286,\n",
      "          705, 16939, 30960,   198, 21017, 18261,    25,   198,   464,  1613,\n",
      "        20170,   286,   705, 16939,     6,   318,   705, 16939,     6,  8754,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|| 205/220 [41:49<09:54, 39.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18438,   391,   644,   257,  3367,  3262,\n",
      "          318,    13,   198, 21017, 18261,    25,   198,    32,  3367,  3262,\n",
      "          318,   257, 21247, 13160,   286,   257,  1271,   286,   336, 35410,\n",
      "          292,    11,  6032,   287,   262,  1296,   286,   257,  3367,  3262,\n",
      "           13,   632,  6032,  6140,   351,   257,  2829,  1808,    11,  6032,\n",
      "          366,  2061,   318,   534,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1438,  1701,   393,   366,  2061,   318,   534,\n",
      "         2802,   338,  1438,  1701,   393,   366,  2061,   318,   534,  2802,\n",
      "          338, 34827,  1438,  1701,   393,   366,  2061,   318,   534,  2988,\n",
      "          338,  1813,  1438,  1701,   393,   366,  2061,   318,   534,  1813,\n",
      "         1438,  1701,   393,   366,  2061,   318,   534,  1813,  1438,  1701,\n",
      "          393,   366,  2061,   318,   534,  1813,  1438,  1701,   393,   366,\n",
      "         2061,   318,   534,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366,  2061,   318,\n",
      "          534,  2988,   338,  1813,  1438,  1701,   393,   366],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 206/220 [41:51<06:56, 29.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705,  3732,   709,   876,  4458,   198,   198, 21017, 18261,\n",
      "           25,   198,   464, 13097,  1628,  2957,   284,   262,  1943,   286,\n",
      "          262,  1628,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|| 207/220 [41:52<04:44, 21.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 15946,   485,   262, 22801,  1296,   286,\n",
      "          705,    66, 34144,  4458,   198, 21017, 18261,    25,   198,    34,\n",
      "        34144,    13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 208/220 [41:53<03:12, 16.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   262,  9546,   705,  8496,\n",
      "          318,   262, 12436,  8348,   656,  2679,    13,   198, 21017, 18261,\n",
      "           25,   198,   464, 12436,   318,   407,   287,  4486,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 209/220 [41:55<02:12, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  1613,    12,    83,\n",
      "         1072, 15942,   326,  8477,   257,  1048, 14376,    13,   198,   198,\n",
      "        21017, 18261,    25,   198,    32,  1613,    12,    83,  1072, 15942,\n",
      "          326,  8477,   257,  1048, 14376,   318,   366,  2395,   263,   526],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 210/220 [41:57<01:32,  9.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705,  7645,  1153,  2637,   198,   198, 21017, 18261,    25,\n",
      "          198,  8291,  1153,   318,   257,  3381,   973,   284,  6901,   257,\n",
      "         1048,   508,   318,   407,  1464,   379,  1363,   393,   379,   670,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 211/220 [41:58<01:02,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8645,   378,   257,  6827,  1262,   262,\n",
      "         1573,   705, 40085,  2569,  4458,   198,   198, 21017, 18261,    25,\n",
      "          198,    40,   716, 16915,   546,   262,  2003,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|| 212/220 [42:00<00:41,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  3041,    12,  4775,   428,  6827,  1262,\n",
      "          281, 12913,  1808,    13,   198,   198, 21017, 23412,    25,   198,\n",
      "         2061,   640,   318,   262,  3249,    30,   198, 21017, 18261,    25,\n",
      "          198,   464,  3249,   318,   379,   262,  2589,    13],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 213/220 [44:21<05:18, 45.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,    34, 47467,  1096,   262,  1708,  6827,\n",
      "          355,   257,  2643,    11,   257,  1808,    11,   393,   281,   409,\n",
      "        20931,    13,   198,   198, 21017, 23412,    25,   198,  2061,   257,\n",
      "         4950,  1110,     0,   198, 21017, 18261,    25,   198,    32,  4950,\n",
      "         1110,     0,   198, 21017, 18261,    25,   198,    32,  4950,  1110,\n",
      "            0,   198, 21017, 18261,    25,   198,    32,  4950,  1110,     0,\n",
      "          198, 21017, 18261,    25,   198,    32,  4950,  1110,     0,   198,\n",
      "        21017, 18261,    25,   198,    32,  4950,  1110,     0,   198, 21017,\n",
      "        18261,    25,   198,    32,  4950,  1110,     0,   198, 21017, 18261,\n",
      "           25,   198,    32,  4950,  1110,     0,   198, 21017, 18261,    25,\n",
      "          198,    32,  4950,  1110,     0,   198, 21017, 18261,    25,   198,\n",
      "           32,  4950,  1110,     0,   198, 21017, 18261,    25,   198,    32,\n",
      "         4950,  1110,     0,   198, 21017, 18261,    25,   198,    32,  4950,\n",
      "         1110,     0,   198, 21017, 18261,    25,   198,    32,  4950,  1110,\n",
      "            0,   198, 21017, 18261,    25,   198,    32,  4950,  1110,     0,\n",
      "          198, 21017, 18261,    25,   198,    32,  4950,  1110,     0,   198,\n",
      "        21017, 18261,    25,   198,    32,  4950,  1110,     0,   198, 21017,\n",
      "        18261,    25,   198,    32,  4950,  1110,     0,   198, 21017, 18261,\n",
      "           25,   198,    32,  4950,  1110,     0,   198, 21017, 18261,    25,\n",
      "          198,    32,  4950,  1110,     0,   198, 21017, 18261,    25,   198,\n",
      "           32,  4950,  1110,     0,   198, 21017, 18261,    25,   198,    32,\n",
      "         4950,  1110,     0,   198, 21017, 18261,    25,   198,    32,  4950,\n",
      "         1110,     0,   198, 21017, 18261,    25,   198,    32,  4950,  1110,\n",
      "            0,   198, 21017, 18261,    25,   198,    32,  4950,  1110,     0,\n",
      "          198, 21017, 18261,    25,   198,    32,  4950,  1110,     0,   198,\n",
      "        21017, 18261,    25,   198,    32,  4950,  1110,     0,   198, 21017,\n",
      "        18261,    25,   198,    32,  4950,  1110,     0,   198, 21017, 18261,\n",
      "           25,   198,    32,  4950,  1110,     0,   198, 21017, 18261,    25,\n",
      "          198,    32,  4950,  1110,     0,   198, 21017, 18261,    25],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|| 214/220 [44:22<03:13, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  2061,   318,   262,  6697,   286,   705,\n",
      "         7527, 30960,   198, 21017, 18261,    25,   198,     6,    49,   291,\n",
      "          372,     6], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 215/220 [44:23<01:55, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 16742,   257,  6171,  5177,   329,   262,\n",
      "         1813, 15942,    13,   198,   198, 21017, 23412,    25,   198, 44140,\n",
      "          198, 21017, 18261,    25,   198,    32,  6171,  5177,   329,   262,\n",
      "         1813, 15942,   318,   366, 27471,   526], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 216/220 [44:24<01:05, 16.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 18378,   262,  1813,  2420,   284,  4155,\n",
      "          477, 22801, 23227,    82,   389, 32213,  9380,    13,   198,   198,\n",
      "        21017, 23412,    25,   198,   464, 10087, 33041,  4950,  7259,    13,\n",
      "          198, 21017, 18261,    25,   198,   464, 10087, 33041,  4950,  7259,\n",
      "           13], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 217/220 [44:25<00:35, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198, 41762,   262,  1708,  6827,   656,   257,\n",
      "         1808,  1262,   366, 24089,   526,   198,   198, 21017, 23412,    25,\n",
      "          198,  1639,   460,  1037,   502,  9439,    13,   198, 21017, 18261,\n",
      "           25,   198, 23722,   345,  1037,   502,  9439,    30],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|| 218/220 [44:27<00:17,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  9487,  1958,   262,  1708,  3709,    25,\n",
      "        17026,    11,  8278,    11, 26241,    13,   198, 20560,    25,   198,\n",
      "           33, 35298,   198, 31087,   198,    51,  8254,   198, 21017, 18261,\n",
      "           25,   198,    33, 35298,   198, 31087,   198,    51,  8254],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 219/220 [46:33<00:43, 43.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  7469,   500,   262,  3381,   705,   343,\n",
      "         1647,  4458,   198, 21017, 18261,    25,   198,     1,    40,   892,\n",
      "          340,   338, 25304,   326,   314,  1101,   287,   257,  2776,   351,\n",
      "          257,   582,   508,   318,   845,  9112,   290,  1464,  5419,   502,\n",
      "          503,    13,  2102,    11,   339,   318,   845, 11334,   290,  1464,\n",
      "         3382,   284,   760,   644,   314,   892,   546,   465,   790,  2551,\n",
      "           13,   314,   892,   340,   338, 25304,   326,   314,  1101,   287,\n",
      "          257,  2776,   351,   257,   582,   508,   318,   845,  9112,   290,\n",
      "         1464,  5419,   502,   503,    13,  2102,    11,   339,   318,   845,\n",
      "        11334,   290,  1464,  3382,   284,   760,   644,   314,   892,   546,\n",
      "          465,   790,  2551,    13,   314,   892,   340,   338, 25304,   326,\n",
      "          314,  1101,   287,   257,  2776,   351,   257,   582,   508,   318,\n",
      "          845,  9112,   290,  1464,  5419,   502,   503,    13,  2102,    11,\n",
      "          339,   318,   845, 11334,   290,  1464,  3382,   284,   760,   644,\n",
      "          314,   892,   546,   465,   790,  2551,    13,   314,   892,   340,\n",
      "          338, 25304,   326,   314,  1101,   287,   257,  2776,   351,   257,\n",
      "          582,   508,   318,   845,  9112,   290,  1464,  5419,   502,   503,\n",
      "           13,  2102,    11,   339,   318,   845, 11334,   290,  1464,  3382,\n",
      "          284,   760,   644,   314,   892,   546,   465,   790,  2551,    13,\n",
      "          314,   892,   340,   338, 25304,   326,   314,  1101,   287,   257,\n",
      "         2776,   351,   257,   582,   508,   318,   845,  9112,   290,  1464,\n",
      "         5419,   502,   503,    13,  2102,    11,   339,   318,   845, 11334,\n",
      "          290,  1464,  3382,   284,   760,   644,   314,   892,   546,   465,\n",
      "          790,  2551,    13,   314,   892,   340,   338, 25304,   326,   314,\n",
      "         1101,   287,   257,  2776,   351,   257,   582,   508,   318,   845,\n",
      "         9112,   290,  1464,  5419,   502,   503,    13,  2102,    11,   339,\n",
      "          318,   845, 11334,   290,  1464,  3382,   284,   760],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 220/220 [46:35<00:00, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
      "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
      "        21017, 46486,    25,   198,  8291, 17660,   705, 14618,     6,   656,\n",
      "         2679,    13,   198, 21017, 18261,    25,   198,    54,   494,   410,\n",
      "         8207,   479,   455,   316,  1658,   479,   455,   316,  1658,    30],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
    "\n",
    "    input_text = format_input(entry)\n",
    "\n",
    "    token_ids = generate(\n",
    "        model=model,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
    "\n",
    "    test_data[i][\"model_response\"] = response_text\n",
    "\n",
    "\n",
    "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
    "    json.dump(test_data, file, indent=4)  # \"indent\" for pretty-printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45e1d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def query_model(\n",
    "    prompt,\n",
    "    model=\"llama3\",\n",
    "    url=\"http://localhost:11434/api/chat\"\n",
    "):\n",
    "    # Create the data payload as a dictionary\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"options\": {     # Settings below are required for deterministic responses\n",
    "            \"seed\": 123,\n",
    "            \"temperature\": 0,\n",
    "            \"num_ctx\": 2048\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a JSON formatted string and encode it to bytes\n",
    "    payload = json.dumps(data).encode(\"utf-8\")\n",
    "\n",
    "    # Create a request object, setting the method to POST and adding necessary headers\n",
    "    request = urllib.request.Request(\n",
    "        url,\n",
    "        data=payload,\n",
    "        method=\"POST\"\n",
    "    )\n",
    "    request.add_header(\"Content-Type\", \"application/json\")\n",
    "\n",
    "    # Send the request and capture the response\n",
    "    response_data = \"\"\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        # Read and decode the response\n",
    "        while True:\n",
    "            line = response.readline().decode(\"utf-8\")\n",
    "            if not line:\n",
    "                break\n",
    "            response_json = json.loads(line)\n",
    "            response_data += response_json[\"message\"][\"content\"]\n",
    "\n",
    "    return response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ea8aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model = \u001b[33m\"\u001b[39m\u001b[33mllama3\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43mquery_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat do Llamas eat?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 35\u001b[39m, in \u001b[36mquery_model\u001b[39m\u001b[34m(prompt, model, url)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Send the request and capture the response\u001b[39;00m\n\u001b[32m     34\u001b[39m response_data = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Read and decode the response\u001b[39;00m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     38\u001b[39m         line = response.readline().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\urllib\\request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\urllib\\request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\urllib\\request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\urllib\\request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\urllib\\request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\urllib\\request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "model = \"llama3\"\n",
    "# result = query_model(\"What do Llamas eat?\", model)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "176606b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for entry in test_data[:3]:\n",
    "#     prompt = (\n",
    "#         f\"Given the input `{format_input(entry)}` \"\n",
    "#         f\"and correct output `{entry['output']}`, \"\n",
    "#         f\"score the model response `{entry['model_response']}`\"\n",
    "#         f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "#     )\n",
    "#     print(\"\\nDataset response:\")\n",
    "#     print(\">>\", entry['output'])\n",
    "#     print(\"\\nModel response:\")\n",
    "#     print(\">>\", entry[\"model_response\"])\n",
    "#     print(\"\\nScore:\")\n",
    "#     print(\">>\", query_model(prompt))\n",
    "#     print(\"\\n-------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61f79eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
    "    scores = []\n",
    "    for entry in tqdm(json_data, desc=\"Scoring entries\"):\n",
    "        prompt = (\n",
    "            f\"Given the input `{format_input(entry)}` \"\n",
    "            f\"and correct output `{entry['output']}`, \"\n",
    "            f\"score the model response `{entry[json_key]}`\"\n",
    "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
    "            f\"Respond with the integer number only.\"\n",
    "        )\n",
    "        score = query_model(prompt, model)\n",
    "        try:\n",
    "            scores.append(int(score))\n",
    "        except ValueError:\n",
    "            print(f\"Could not convert score: {score}\")\n",
    "            continue\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "663986ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:   0%|          | 0/220 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  28%|       | 61/220 [02:49<07:42,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: **Subject: 20**\n",
      "\n",
      "How does a virus infect a cell?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries:  71%|   | 156/220 [07:01<04:54,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not convert score: I'd be happy to help!\n",
      "\n",
      "The model's response for \"Tomato\" was incorrect, so I'll give it a score of 0.\n",
      "\n",
      "The model's response for \"Vegetable\" was also incorrect, so I'll give it a score of 0 again.\n",
      "\n",
      "Here are the scores:\n",
      "\n",
      "* Tomato: 0\n",
      "* Vegetable: 0\n",
      "\n",
      "So, the average score is (0 + 0) / 2 = 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scoring entries: 100%|| 220/220 [09:48<00:00,  2.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[95,\n",
       " 4,\n",
       " 4,\n",
       " 20,\n",
       " 100,\n",
       " 20,\n",
       " 60,\n",
       " 80,\n",
       " 20,\n",
       " 100,\n",
       " 44,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 98,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 85,\n",
       " 20,\n",
       " 80,\n",
       " 60,\n",
       " 4,\n",
       " 20,\n",
       " 95,\n",
       " 85,\n",
       " 6,\n",
       " 60,\n",
       " 85,\n",
       " 100,\n",
       " 20,\n",
       " 60,\n",
       " 60,\n",
       " 4,\n",
       " 20,\n",
       " 85,\n",
       " 20,\n",
       " 2,\n",
       " 4,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 0,\n",
       " 60,\n",
       " 20,\n",
       " 20,\n",
       " 95,\n",
       " 95,\n",
       " 20,\n",
       " 85,\n",
       " 98,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 80,\n",
       " 67,\n",
       " 20,\n",
       " 40,\n",
       " 85,\n",
       " 60,\n",
       " 4,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 100,\n",
       " 20,\n",
       " 4,\n",
       " 100,\n",
       " 20,\n",
       " 20,\n",
       " 60,\n",
       " 20,\n",
       " 4,\n",
       " 100,\n",
       " 94,\n",
       " 67,\n",
       " 20,\n",
       " 80,\n",
       " 60,\n",
       " 4,\n",
       " 4,\n",
       " 20,\n",
       " 20,\n",
       " 95,\n",
       " 20,\n",
       " 12,\n",
       " 80,\n",
       " 20,\n",
       " 98,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 0,\n",
       " 80,\n",
       " 98,\n",
       " 12,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 0,\n",
       " 20,\n",
       " 60,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 96,\n",
       " 20,\n",
       " 20,\n",
       " 95,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 95,\n",
       " 80,\n",
       " 40,\n",
       " 20,\n",
       " 20,\n",
       " 98,\n",
       " 20,\n",
       " 4,\n",
       " 100,\n",
       " 50,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 60,\n",
       " 98,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 100,\n",
       " 20,\n",
       " 80,\n",
       " 80,\n",
       " 40,\n",
       " 20,\n",
       " 60,\n",
       " 0,\n",
       " 20,\n",
       " 20,\n",
       " 4,\n",
       " 4,\n",
       " 20,\n",
       " 0,\n",
       " 4,\n",
       " 80,\n",
       " 20,\n",
       " 95,\n",
       " 95,\n",
       " 100,\n",
       " 20,\n",
       " 95,\n",
       " 4,\n",
       " 80,\n",
       " 95,\n",
       " 80,\n",
       " 80,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 0,\n",
       " 60,\n",
       " 85,\n",
       " 20,\n",
       " 98,\n",
       " 43,\n",
       " 98,\n",
       " 80,\n",
       " 4,\n",
       " 95,\n",
       " 98,\n",
       " 20,\n",
       " 100,\n",
       " 80,\n",
       " 40,\n",
       " 4,\n",
       " 85,\n",
       " 20,\n",
       " 4,\n",
       " 20,\n",
       " 20,\n",
       " 80,\n",
       " 20,\n",
       " 0,\n",
       " 20,\n",
       " 60,\n",
       " 40,\n",
       " 90,\n",
       " 96,\n",
       " 2,\n",
       " 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_model_scores(test_data,'model_response')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35aaaa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b75ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [95,\n",
    " 4,\n",
    " 4,\n",
    " 20,\n",
    " 100,\n",
    " 20,\n",
    " 60,\n",
    " 80,\n",
    " 20,\n",
    " 100,\n",
    " 44,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 60,\n",
    " 60,\n",
    " 20,\n",
    " 20,\n",
    " 4,\n",
    " 98,\n",
    " 20,\n",
    " 20,\n",
    " 4,\n",
    " 85,\n",
    " 20,\n",
    " 80,\n",
    " 60,\n",
    " 4,\n",
    " 20,\n",
    " 95,\n",
    " 85,\n",
    " 6,\n",
    " 60,\n",
    " 85,\n",
    " 100,\n",
    " 20,\n",
    " 60,\n",
    " 60,\n",
    " 4,\n",
    " 20,\n",
    " 85,\n",
    " 20,\n",
    " 2,\n",
    " 4,\n",
    " 20,\n",
    " 20,\n",
    " 80,\n",
    " 60,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 60,\n",
    " 20,\n",
    " 20,\n",
    " 80,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 0,\n",
    " 60,\n",
    " 20,\n",
    " 20,\n",
    " 95,\n",
    " 95,\n",
    " 20,\n",
    " 85,\n",
    " 98,\n",
    " 20,\n",
    " 20,\n",
    " 60,\n",
    " 80,\n",
    " 67,\n",
    " 20,\n",
    " 40,\n",
    " 85,\n",
    " 60,\n",
    " 4,\n",
    " 20,\n",
    " 80,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 100,\n",
    " 20,\n",
    " 4,\n",
    " 100,\n",
    " 20,\n",
    " 20,\n",
    " 60,\n",
    " 20,\n",
    " 4,\n",
    " 100,\n",
    " 94,\n",
    " 67,\n",
    " 20,\n",
    " 80,\n",
    " 60,\n",
    " 4,\n",
    " 4,\n",
    " 20,\n",
    " 20,\n",
    " 95,\n",
    " 20,\n",
    " 12,\n",
    " 80,\n",
    " 20,\n",
    " 98,\n",
    " 80,\n",
    " 20,\n",
    " 20,\n",
    " 0,\n",
    " 80,\n",
    " 98,\n",
    " 12,\n",
    " 20,\n",
    " 20,\n",
    " 80,\n",
    " 20,\n",
    " 20,\n",
    " 20,\n",
    " 0,\n",
    " 20,\n",
    " 60,\n",
    " 80,\n",
    " 20,\n",
    " 20,\n",
    " 96,\n",
    " 20,\n",
    " 20,\n",
    " 95,\n",
    " 20,\n",
    " 20,\n",
    " 4,\n",
    " 95,\n",
    " 80,\n",
    " 40,\n",
    " 20,\n",
    " 20,\n",
    " 98,\n",
    " 20,\n",
    " 4,\n",
    " 100,\n",
    " 50,\n",
    " 20,\n",
    " 20,\n",
    " 80,\n",
    " 60,\n",
    " 98,\n",
    " 20,\n",
    " 4,\n",
    " 20,\n",
    " 100,\n",
    " 20,\n",
    " 80,\n",
    " 80,\n",
    " 40,\n",
    " 20,\n",
    " 60,\n",
    " 0,\n",
    " 20,\n",
    " 20,\n",
    " 4,\n",
    " 4,\n",
    " 20,\n",
    " 0,\n",
    " 4,\n",
    " 80,\n",
    " 20,\n",
    " 95,\n",
    " 95,\n",
    " 100,\n",
    " 20,\n",
    " 95,\n",
    " 4,\n",
    " 80,\n",
    " 95,\n",
    " 80,\n",
    " 80,\n",
    " 20,\n",
    " 80,\n",
    " 20,\n",
    " 20,\n",
    " 80,\n",
    " 0,\n",
    " 60,\n",
    " 85,\n",
    " 20,\n",
    " 98,\n",
    " 43,\n",
    " 98,\n",
    " 80,\n",
    " 4,\n",
    " 95,\n",
    " 98,\n",
    " 20,\n",
    " 100,\n",
    " 80,\n",
    " 40,\n",
    " 4,\n",
    " 85,\n",
    " 20,\n",
    " 4,\n",
    " 20,\n",
    " 20,\n",
    " 80,\n",
    " 20,\n",
    " 0,\n",
    " 20,\n",
    " 60,\n",
    " 40,\n",
    " 90,\n",
    " 96,\n",
    " 2,\n",
    " 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bfe01962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2d845aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.73853211009175"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccad9e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
